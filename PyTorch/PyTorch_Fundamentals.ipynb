{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.<br/>\n",
    "\n",
    "**1️⃣N-d Tensor:**\n",
    "- `0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.\n",
    "- `1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "- `2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.\n",
    "- `3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.\n",
    "\n",
    "**2️⃣Tensor datatypes:**<br/>\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types). Some are specific for CPU and some are better for GPU.<br/>\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).<br/>\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.<br/>\n",
    "\n",
    "**3️⃣Getting information from tensors:**<br/>\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "**4️⃣Math Operations:**<br/>\n",
    "* Addition ⇒ `a+b `or `torh.add(a, b)`\n",
    "* Substraction ⇒ `a-b `or `torh.sub(a, b)`\n",
    "* Multiplication (element-wise) ⇒ `a*b `\n",
    "* Division ⇒ `a/b `or `torh.div(a, b)`\n",
    "* Matrix multiplication ⇒ \"`@`\" in Python is the symbol for matrix multiplication. [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) or [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)\n",
    "  \n",
    "**5️⃣Special Arrays**<br/>\n",
    "- zeros\n",
    "- ones\n",
    "- empty\n",
    "- eye\n",
    "- full<br/>\n",
    "\n",
    "Using [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively.\n",
    "\n",
    "**6️⃣Random Arrays**\n",
    "- `torch.rand:` Create a n*m tensor filled with random numbers from a uniform distribution on the interval [0, 1)\n",
    "- `torch.randn:` Create a n*m tensor filled with random numbers from a normal distribution with mean 0 and variance 1. \n",
    "- `torch.randint:` Create a n*m tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).\n",
    "  \n",
    "**7️⃣Indexing & Slicing**\n",
    "- `Indexing`\n",
    "  - Accessing individual elements:  use integer indices to specify the position of the element you want to retrieve.\n",
    "- `Slicing`\n",
    "  - Extracting sub-tensors: Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator.\n",
    "    - `start:end` (exclusive end)\n",
    "    - `start:` (from start to end of dimension)\n",
    "    - `:end` (from beginning to end of dimension)\n",
    "    - `:` (all elements)\n",
    "    - `start:end:step` (start to end with given step)\n",
    "  - Slicing with steps: You can include a step to skip elements in the slice. `start:end:step`\n",
    "\n",
    "**8️⃣`Unsqueeze & unsqueeze:`**\n",
    "- The squeeze() method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.\n",
    "- The unsqueeze() method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  #  torch.__version__  -> '2.5.1+cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scalar, Vector, Column vector, Matrix, & N-d Tensor**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 0D tensor (Scalar)\n",
    "torch.tensor(4/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([1, 2, 3]) --> a.__class__ = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Creating a 1D tensor (Vector)\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(f\"{a = } --> {a.__class__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 2D tensor (Column vector)\n",
    "torch.tensor([[1], [2], [3], [4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 2D tensor (Matrix)\n",
    "torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 2, 5],\n",
       "         [3, 4, 0, 8]],\n",
       "\n",
       "        [[5, 6, 6, 7],\n",
       "         [4, 8, 1, 2]],\n",
       "\n",
       "        [[1, 1, 8, 9],\n",
       "         [0, 0, 2, 3]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 3D tensor\n",
    "torch.tensor(\n",
    "    [[[1, 2, 2 , 5],\n",
    "      [3, 4, 0 , 8]],\n",
    "\n",
    "     [[5, 6, 6, 7],\n",
    "      [4, 8, 1, 2]],\n",
    "\n",
    "     [[1, 1, 8, 9],\n",
    "      [0, 0, 2, 3]]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 5, 4],\n",
       "          [3, 4, 1, 0]],\n",
       "\n",
       "         [[5, 6, 2, 3],\n",
       "          [7, 8, 6, 4]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 4D tensor (Matrix)\n",
    "torch.tensor(\n",
    "    [[[[1, 2, 5, 4],\n",
    "       [3, 4, 1, 0]],\n",
    "      [[5, 6, 2, 3],\n",
    "       [7, 8, 6, 4]]]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting information from tensors:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([1.0, 5.0, 6.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor(1.3333, dtype=torch.float64) --> a.shape = torch.Size([]) --> a.ndim = 0 --> a.size() = torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.3330, dtype=torch.float16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 0D tensor (Scalar)\n",
    "a = torch.tensor(4/3, dtype=torch.float64, device=\"cpu\")\n",
    "print(f\"{a = } --> {a.shape = } --> {a.ndim = } --> {a.size() = }\")\n",
    "a.type(torch.float16)     # Convert into float16 or a.short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tuple([(1, 2), (3, 4), (5, 6)])\n",
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]])\n",
      "a.shape = torch.Size([2, 2, 2, 2]) --> a.ndim = 4 --> a.size() = torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Creating a 2D tensor (Matrix)\n",
    "a = torch.tensor(\n",
    "    [[[[1, 2],\n",
    "       [3, 4]],\n",
    "      [[5, 6],\n",
    "       [7, 8]]],\n",
    "     [[[9, 10],\n",
    "       [11, 12]],\n",
    "      [[13, 14],\n",
    "       [15, 16]]]]\n",
    "    )\n",
    "print(f\"{a = }\\n{a.shape = } --> {a.ndim = } --> {a.size() = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.), tensor(1.))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Mean, std\n",
    "a = torch.tensor([1, 2, 3])\n",
    "a.float().mean(), a.type(torch.float32).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[[[ 1,  9],\n",
      "          [ 5, 13]],\n",
      "\n",
      "         [[ 3, 11],\n",
      "          [ 7, 15]]],\n",
      "\n",
      "\n",
      "        [[[ 2, 10],\n",
      "          [ 6, 14]],\n",
      "\n",
      "         [[ 4, 12],\n",
      "          [ 8, 16]]]])\n",
      "a.shape = torch.Size([2, 2, 2, 2]) --> a.ndim = 4 --> a.size() = torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Creating a 2D tensor (Matrix)\n",
    "a = torch.tensor(\n",
    "    [[[[1, 2],\n",
    "       [3, 4]],\n",
    "      [[5, 6],\n",
    "       [7, 8]]],\n",
    "     [[[9, 10],\n",
    "       [11, 12]],\n",
    "      [[13, 14],\n",
    "       [15, 16]]]]\n",
    "    )\n",
    "a = a.T\n",
    "print(f\"{a = }\\n{a.shape = } --> {a.ndim = } --> {a.size() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 5],\n",
       "         [7, 3]]),\n",
       " tensor([[8, 9],\n",
       "         [6, 9]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(10, (2, 2))\n",
    "b = torch.randint(10, (2, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9, 14],\n",
       "         [13, 12]]),\n",
       " tensor([[-7, -4],\n",
       "         [ 1, -6]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a, b, ), torch.sub(a, b, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 8, 45],\n",
       "         [42, 27]]),\n",
       " tensor([[38, 54],\n",
       "         [74, 90]]),\n",
       " tensor([[38, 54],\n",
       "         [74, 90]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b, a @ b, torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.5556],\n",
       "        [1.1667, 0.3333]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([4, 3], fill_value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4657, 0.2328, 0.4527],\n",
       "        [0.5871, 0.4086, 0.1272],\n",
       "        [0.6373, 0.2421, 0.7312],\n",
       "        [0.7224, 0.1992, 0.6948]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.rand((4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2138, -1.3780, -0.0546],\n",
       "        [ 0.4515,  0.7858, -1.0884],\n",
       "        [-0.5599, -0.9336,  0.0479],\n",
       "        [-0.0844, -0.1471,  0.7590]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.randn((4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  3,  9],\n",
       "        [11,  2, 10],\n",
       "        [ 8,  3,  3],\n",
       "        [10, 11,  2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.randint(2, 13, (4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 7, 6, 4, 5, 2, 9, 1, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random permutation of integers from 0 to 9\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing & Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5599, -0.9336,  0.0479, -0.0844, -0.1471,  0.7590,  0.1466, -1.0041,\n",
       "         -0.7882, -0.8074, -0.2957, -0.1462]),\n",
       " tensor([-0.5599]),\n",
       " tensor(-0.5599),\n",
       " tensor([-0.5599,  0.0479, -1.0041]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(12)\n",
    "a, a[0:1], a[0], a[[0, 2, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1413, -1.6453,  1.8908,  0.5526,  1.9144]),\n",
       " tensor([-1.1413, -1.6453,  1.8908,  0.5526,  1.9144]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:12:2], a[2::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2805,  1.0472,  1.0210,  0.9056, -0.4245],\n",
       "        [ 0.8547,  1.4893,  1.0438,  0.3598,  1.0205],\n",
       "        [-0.4142,  1.1937, -0.3547, -0.2390, -0.1566]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0210,  0.9056],\n",
       "         [ 1.0438,  0.3598],\n",
       "         [-0.3547, -0.2390]]),\n",
       " tensor([[ 1.0210,  0.9056],\n",
       "         [ 1.0438,  0.3598],\n",
       "         [-0.3547, -0.2390]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:3, 2:-1], a[:, 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3641,  0.4331,  0.5895, -1.2568,  0.4411],\n",
       "         [-0.2782, -0.2588, -0.4724,  1.0558,  0.5683]]),\n",
       " tensor([[ 0.3641,  0.4331,  0.5895, -1.2568,  0.4411],\n",
       "         [-0.2782, -0.2588, -0.4724,  1.0558,  0.5683]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:2], a[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5895, -1.2568,  0.4411],\n",
       "        [ 1.9573, -0.3660, -0.2266]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::2, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.2969e-01,  1.1980e+00, -1.0833e+00,  3.5402e-01,  7.9477e-01,\n",
       "           2.3819e+00, -3.7064e-01],\n",
       "         [-7.9222e-01, -8.3236e-01, -3.2613e-01,  1.7579e+00,  3.6650e-01,\n",
       "          -3.3034e-02, -1.3126e+00],\n",
       "         [-9.2532e-01, -3.8545e-01, -5.3512e-01,  4.0278e-01,  1.1849e-01,\n",
       "           2.9048e+00,  1.4602e+00],\n",
       "         [ 1.5539e+00, -1.5911e+00, -2.1023e-01, -9.3761e-01,  5.8109e-01,\n",
       "          -2.9350e-01, -8.0874e-01],\n",
       "         [-3.1397e-01, -1.9417e+00, -1.8543e+00,  2.7558e-01, -5.9811e-01,\n",
       "          -3.8076e-01,  3.5677e-03],\n",
       "         [ 2.4633e-01,  1.3368e-01, -1.0755e+00,  1.9913e+00, -1.4785e+00,\n",
       "          -1.3697e+00, -5.6596e-01]],\n",
       "\n",
       "        [[ 1.1672e+00, -1.7709e+00, -4.4624e-01,  7.9434e-01,  7.4588e-01,\n",
       "           3.8383e-01,  4.3685e-01],\n",
       "         [ 8.1806e-01, -1.0156e+00, -5.4061e-01,  1.5879e-01, -4.2923e-01,\n",
       "           4.3937e-01, -1.3256e-01],\n",
       "         [ 1.7277e+00,  9.3084e-01,  1.4519e+00, -4.9755e-01,  6.5133e-01,\n",
       "          -2.1107e-01,  2.7395e-01],\n",
       "         [-1.1969e+00, -6.0858e-01,  8.9590e-01,  2.1258e+00, -2.7747e-02,\n",
       "           3.8384e-01, -1.7151e+00],\n",
       "         [ 4.1471e-01,  8.3979e-01,  3.4220e-01, -2.3196e+00,  7.6225e-01,\n",
       "           6.2045e-01,  2.3008e-01],\n",
       "         [-1.7236e+00,  7.5226e-01, -5.6694e-01,  7.9610e-01, -3.5459e-01,\n",
       "          -1.5467e+00,  5.2085e-01]],\n",
       "\n",
       "        [[ 4.6108e-01, -9.1255e-01, -6.7037e-01, -1.5016e+00, -2.4462e+00,\n",
       "           2.2535e-01,  6.0805e-01],\n",
       "         [-6.7050e-02, -2.5667e-01,  6.6530e-01,  3.4849e-01, -3.0517e-01,\n",
       "           1.1489e+00,  1.2861e+00],\n",
       "         [ 4.6786e-01,  4.2048e-01,  8.6716e-01,  1.0610e-01,  1.1346e+00,\n",
       "           7.6687e-01,  9.1297e-01],\n",
       "         [ 2.1123e-01,  1.2541e-01, -7.8015e-01, -6.8554e-02, -8.3586e-01,\n",
       "          -4.6496e-01, -4.7118e-01],\n",
       "         [-3.6919e-01,  1.8396e-01,  9.3915e-01, -6.2772e-01, -3.8302e-02,\n",
       "          -1.0608e+00,  9.2034e-02],\n",
       "         [ 1.1882e+00,  2.4564e-03, -1.2157e+00, -2.9878e-01,  8.1731e-03,\n",
       "          -4.7928e-01,  1.1607e+00]],\n",
       "\n",
       "        [[ 1.7413e+00, -1.6035e+00, -1.5472e+00,  1.4353e-02, -5.9002e-01,\n",
       "           4.7920e-01,  1.1845e+00],\n",
       "         [-1.5000e+00,  7.0517e-01,  1.8130e-01,  4.5851e-01, -8.7532e-01,\n",
       "          -1.0450e+00, -2.0075e-01],\n",
       "         [-4.9694e-01, -6.8697e-01,  1.2904e+00, -6.2279e-01,  1.2720e-01,\n",
       "          -5.2066e-01, -2.1612e-01],\n",
       "         [ 3.5481e-01,  4.4950e-01, -5.7936e-01,  4.6835e-01,  8.1213e-01,\n",
       "           4.0012e-01,  1.1803e-01],\n",
       "         [ 3.2844e-01,  1.8744e-01, -1.4583e-01, -9.2184e-01,  7.1015e-01,\n",
       "          -1.0031e+00,  1.2937e+00],\n",
       "         [-1.8393e-01, -5.1315e-01,  1.0776e+00, -1.0983e+00, -6.4279e-01,\n",
       "          -7.2658e-01,  7.5722e-01]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 6, 7)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.8959,  2.1258],\n",
       "          [ 0.3422, -2.3196]]]),\n",
       " tensor([[[ 0.8959,  2.1258],\n",
       "          [ 0.3422, -2.3196]]]),\n",
       " tensor([[ 0.8959,  2.1258],\n",
       "         [ 0.3422, -2.3196]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:2, 3:5, 2:4], a[[1], 3:5, 2:4], a[1, 3:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1672, -1.7709, -0.4462,  0.7943,  0.7459,  0.3838,  0.4369],\n",
       "         [ 0.8181, -1.0156, -0.5406,  0.1588, -0.4292,  0.4394, -0.1326],\n",
       "         [ 1.7277,  0.9308,  1.4519, -0.4976,  0.6513, -0.2111,  0.2740],\n",
       "         [-1.1969, -0.6086,  0.8959,  2.1258, -0.0277,  0.3838, -1.7151],\n",
       "         [ 0.4147,  0.8398,  0.3422, -2.3196,  0.7623,  0.6204,  0.2301],\n",
       "         [-1.7236,  0.7523, -0.5669,  0.7961, -0.3546, -1.5467,  0.5208]]),\n",
       " tensor([[-0.3706, -1.3126,  1.4602, -0.8087,  0.0036, -0.5660],\n",
       "         [ 0.4369, -0.1326,  0.2740, -1.7151,  0.2301,  0.5208],\n",
       "         [ 0.6081,  1.2861,  0.9130, -0.4712,  0.0920,  1.1607],\n",
       "         [ 1.1845, -0.2007, -0.2161,  0.1180,  1.2937,  0.7572]]),\n",
       " tensor([[-0.3706, -1.3126,  1.4602, -0.8087,  0.0036, -0.5660],\n",
       "         [ 0.4369, -0.1326,  0.2740, -1.7151,  0.2301,  0.5208],\n",
       "         [ 0.6081,  1.2861,  0.9130, -0.4712,  0.0920,  1.1607],\n",
       "         [ 1.1845, -0.2007, -0.2161,  0.1180,  1.2937,  0.7572]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1], a[:, :, -1], a[..., -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsqueeze & unsqueeze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of tensor_a: torch.Size([1, 3, 1, 4, 1])\n",
      "Squeezed shape of tensor_b: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing all singleton dimensions\n",
    "tensor_a = torch.randn(1, 3, 1, 4, 1)\n",
    "print(\"Original shape of tensor_a:\", tensor_a.shape)  # Output: torch.Size([1, 3, 1, 4, 1])\n",
    "\n",
    "tensor_b = tensor_a.squeeze()\n",
    "print(\"Squeezed shape of tensor_b:\", tensor_b.shape)  # Output: torch.Size([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of a: torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(0).shape = torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(1).shape = torch.Size([2, 3, 1, 4])\n",
      "a.squeeze(3).shape = torch.Size([2, 1, 3, 4])\n",
      "a.squeeze().shape = torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing a specific singleton dimension\n",
    "a = torch.randn(2, 1, 3, 1, 4)\n",
    "print(\"Original shape of a:\", a.shape)  # Output: torch.Size([2, 1, 3, 1, 4])\n",
    "\n",
    "# Remove the first dimension (index 0) which is not 1, so no change is done; Output: torch.Size([2, 1, 3, 1, 4])\n",
    "print(f\"{a.squeeze(0).shape = }\")\n",
    "\n",
    "# Remove the second dimension (index 1) which is size 1; Output: torch.Size([2, 3, 1, 4])\n",
    "print(f\"{a.squeeze(1).shape = }\")\n",
    "\n",
    "# Remove the fourth dimension (index 3) which is size 1; Output: torch.Size([2, 1, 3, 4])\n",
    "print(f\"{a.squeeze(3).shape = }\")\n",
    "\n",
    "print(f\"{a.squeeze().shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[ 0.8279,  1.1309],\n",
      "        [-0.8629,  2.1094]])\n",
      "b.unsqueeze(0) = tensor([[[ 0.8279,  1.1309],\n",
      "         [-0.8629,  2.1094]]]) --> b.unsqueeze(0).shape = torch.Size([1, 2, 2])\n",
      "b.unsqueeze(1) = tensor([[[ 0.8279,  1.1309]],\n",
      "\n",
      "        [[-0.8629,  2.1094]]]) --> b.unsqueeze(1).shape = torch.Size([2, 1, 2])\n",
      "b.unsqueeze(2) = tensor([[[ 0.8279],\n",
      "         [ 1.1309]],\n",
      "\n",
      "        [[-0.8629],\n",
      "         [ 2.1094]]]) --> b.unsqueeze(2).shape = torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(2, 2)\n",
    "print(\"Original:\", b)  # Output: torch.Size([3, 4])\n",
    "\n",
    "# Add dimension at the beginning (index 0); # Output: torch.Size([1, 3, 4])\n",
    "print(f\"{b.unsqueeze(0) = } --> {b.unsqueeze(0).shape = }\")\n",
    "# Add dimension in between the two dimensions (index 1); Output: torch.Size([3, 1, 4])\n",
    "print(f\"{b.unsqueeze(1) = } --> {b.unsqueeze(1).shape = }\")\n",
    "\n",
    "# Add dimension at the end (index 2); Output: torch.Size([3, 4, 1])\n",
    "print(f\"{b.unsqueeze(2) = } --> {b.unsqueeze(2).shape = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
