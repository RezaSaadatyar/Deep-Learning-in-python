{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras      # print(keras.__version__, tf.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Step 1. Load data*<br/>\n",
    "[Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data.keys: dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])\n",
      "\n",
      " Inputs:[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]]\n",
      "\n",
      " Labels:[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
      "\n",
      " Target_names:['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "print(f\"Data.keys: {data.keys()}\")                                      # Information about dataset\n",
    "print(f\"\\n Inputs:{data['data']}\")                                      # Input data\n",
    "print(f\"\\n Labels:{data['target']}\")                                    # Targets or Labels\n",
    "print(f\"\\n Target_names:{data['feature_names']}\")                       # Features name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data.shape: (20640, 8)\n",
      "labels.shape: (20640,)\n"
     ]
    }
   ],
   "source": [
    "input_data = data['data']                                         # Input data\n",
    "labels_data = data['target']                                      # Targets or Labels\n",
    "print(f\"input_data.shape: {input_data.shape}\")\n",
    "print(f\"labels.shape: {labels_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Step 2: [Split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)*<br/>\n",
    "Split dataset into random train and test subsets<br/>\n",
    "Split train into random train and validation subsets<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:(11610, 8)\n",
      "x_test.shape:(5160, 8)\n",
      "x_validation.shape:(3870, 8)\n",
      "y_train.shape:(11610,)\n",
      "y_test.shape:(5160,)\n",
      "y_validation.shape:(3870,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(input_data, labels_data, test_size=0.25)  # Split data into train & test\n",
    "x_train, x_validation, y_train, y_validation = model_selection.train_test_split(x_train, y_train, test_size=0.25) # Split train into train & validation\n",
    "print(f\"x_train.shape:{x_train.shape}\")\n",
    "print(f\"x_test.shape:{x_test.shape}\")\n",
    "print(f\"x_validation.shape:{x_validation.shape}\")\n",
    "print(f\"y_train.shape:{y_train.shape}\")\n",
    "print(f\"y_test.shape:{y_test.shape}\")\n",
    "print(f\"y_validation.shape:{y_validation.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Step 3: [Normalize data](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = preprocessing.StandardScaler()\n",
    "x_train_norm = norm.fit_transform(x_train)\n",
    "x_validation_norm = norm.transform(x_validation)\n",
    "x_test_norm = norm.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4: Wide & Deep Network*<br/>\n",
    "[Functional API](https://keras.io/guides/functional_api/)<br/>\n",
    "[Concatenate layer](https://keras.io/api/layers/merging_layers/concatenate/)<br/>\n",
    "[Article]()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
