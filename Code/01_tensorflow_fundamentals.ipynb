{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to Deep Learning with Keras and TensorFlow in Python**\n",
    "\n",
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a framework for building and running machine learning models using tensors.<br/>\n",
    "A tensor generalizes vectors and matrices to higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base data types.<br/>\n",
    "\n",
    "‚ñ™ Command (run in terminal, not Python): `pip install tensorflow`<br/>\n",
    "‚ñ™ GPU version: `pip install tensorflow-gpu`<br/>\n",
    "\n",
    "In TensorFlow, code can be executed in two primary modes: `Eager Execution` and `Graph Execution`. These modes determine how operations are processed and optimized, which can impact performance, debugging, and deployment.<br/>\n",
    "\n",
    "**Eager Execution** in TensorFlow 2.x is an imperative mode where operations execute instantly without a computational graph, offering an interactive, Python-like coding experience. Eager execution is enabled by default.<br/>\n",
    "\n",
    "`Advantages:`<br/>\n",
    "‚ñ™ Simplifies debugging with tools like print() or a debugger.<br/> \n",
    "‚ñ™ Great for rapid prototyping and experimentation.<br/>\n",
    "‚ñ™ Eliminates the need to build graphs or sessions manually.<br/>\n",
    "\n",
    "`Disadvantages:`<br/>\n",
    "‚ñ™ Less efficient for large-scale or production use due to lack of graph optimization.<br/>\n",
    "‚ñ™ Not suitable for hardware relying on static graphs (e.g., TensorFlow Lite, TensorFlow Serving).<br/>\n",
    "\n",
    "**Graph Execution** builds a computational graph of operations, compiles it, and executes it as a whole. Default in TensorFlow 1.x, it‚Äôs still usable in TensorFlow 2.x by disabling eager execution or using specific APIs. Instead of running operations immediately, TensorFlow creates a graph of nodes (operations) and edges (tensors), optimizes it (e.g., removing redundancies or fusing operations), and executes it in a tf.Disable eager execution to use graph mode ‚Üí `tf.compat.v1.disable_eager_execution()` or the `tf.function decorator` to convert eager code into a graph.\n",
    "<br/>\n",
    "\n",
    "`Advantages:`<br/>\n",
    "‚ñ™ Optimized for performance on GPUs/TPUs via graph optimizations.<br/>\n",
    "‚ñ™ Ideal for production deployment needing static graphs (e.g., mobile, servers).<br/> \n",
    "‚ñ™ Supports distributed computing and automatic gradient computation.<br/>\n",
    "\n",
    "`Disadvantages:`<br/>\n",
    "‚ñ™ Debugging is harder as operations run only when the graph executes.<br/>\n",
    "‚ñ™ Requires session management and explicit data feeding, which is less intuitive.<br/>\n",
    "\n",
    "**TensorFlow Outline:**<br/>\n",
    "‚ñ™ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)<br/>\n",
    "‚ñ™ Scalar, Vector, Column Vector, Matrix, & N-d Tensor<br/>\n",
    "‚ñ™ Getting information from tensors<br/>\n",
    "‚ñ™ Math Operations<br/>\n",
    "‚ñ™ Special Arrays<br/>\n",
    "‚ñ™ Random Arrays<br/>\n",
    "‚ñ™ Indexing & Slicing<br/>\n",
    "‚ñ™ Unsqueeze & squeeze<br/>\n",
    "‚ñ™ TensorFlow Tensors & NumPy<br/>\n",
    "‚ñ™ Array Manipulation<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'TensorFlow Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f3dc08 size=\"4.5\" face=\"Arial\"><b>1Ô∏è‚É£ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)</b></font><br/>\n",
    "`CPU:`<br/>\n",
    "‚ñ™ Designed for general-purpose computing.<br/>\n",
    "‚ñ™ Optimized for sequential tasks.<br/>\n",
    "‚ñ™ Has a few powerful cores.<br/>\n",
    "‚ñ™ Excellent at handling complex logic and single-threaded applications.<br/>\n",
    "  \n",
    "`GPU:`<br/>\n",
    "‚ñ™ Designed for parallel processing.<br/>\n",
    "‚ñ™ Has thousands of smaller, less powerful cores.<br/>\n",
    "‚ñ™ GPUs offer far faster numerical computing than CPUs.<br/>\n",
    "‚ñ™ Optimized for tasks that can be divided into many independent calculations.<br/>\n",
    "‚ñ™ Excellent for tasks like matrix operations, which are common in deep learning.<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means\n",
    "# \"run this on the command line\".\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      "Using device: /CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability by listing physical devices and checking if any GPU is present\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU') != []}\")\n",
    "# Example output: GPU Available: False (if no GPU is detected)\n",
    "\n",
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "# Print the device being used for computation\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#08f308 size=\"4.5\" face=\"Arial\"><b>2Ô∏è‚É£ Scalar, Vector, Column Vector, Matrix, & N-d Tensor</b></font><br/>\n",
    "A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.<br/>\n",
    "‚ñ™ `0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.<br/>\n",
    "‚ñ™ `1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "‚ñ™ `2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.<br/>\n",
    "‚ñ™ `3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 1.3333333730697632\n"
     ]
    }
   ],
   "source": [
    "# Create a scalar (0-dimensional tensor) with a constant value of 4/3 and specify its data type as float32\n",
    "scalar = tf.constant(4/3, dtype=tf.float32)\n",
    "# Print the scalar tensor\n",
    "print(f\"Scalar: {scalar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [1 2 3] --> vector.__class__ = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Column Vector:\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "# Create a vector (1-dimensional tensor) with a list of values [1, 2, 3]\n",
    "vector = tf.constant([1, 2, 3])\n",
    "# Print the vector tensor and its class type\n",
    "print(f\"Vector: {vector} --> {vector.__class__ = }\")\n",
    "\n",
    "# Create a column vector (2-dimensional tensor) with a nested list of values [[1], [2], [3], [4]]\n",
    "col_vector = tf.constant([[1], [2], [3], [4]])\n",
    "# Print the column vector tensor\n",
    "print(f\"Column Vector:\\n{col_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix (2-dimensional tensor) with a nested list of values [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "# Print the matrix tensor\n",
    "print(f\"Matrix:\\n{matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Tensor:\n",
      "[[[1 2 2 5]\n",
      "  [3 4 0 8]]\n",
      "\n",
      " [[5 6 6 7]\n",
      "  [4 8 1 2]]\n",
      "\n",
      " [[1 1 8 9]\n",
      "  [0 0 2 3]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor (3-dimensional tensor) with a nested list of values\n",
    "# The structure is: 3 layers, each containing 2 rows and 4 columns\n",
    "tensor_3d = tf.constant([[[1, 2, 2, 5], [3, 4, 0, 8]],\n",
    "                         [[5, 6, 6, 7], [4, 8, 1, 2]],\n",
    "                         [[1, 1, 8, 9], [0, 0, 2, 3]]])\n",
    "# Print the 3D tensor\n",
    "print(f\"3D Tensor:\\n{tensor_3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D Tensor:\n",
      "[[[[1 2 5 4]\n",
      "   [3 4 1 0]]\n",
      "\n",
      "  [[5 6 2 3]\n",
      "   [7 8 6 4]]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 4D tensor (4-dimensional tensor) with a deeply nested list of values\n",
    "# The structure is: 1 batch, 2 layers, each containing 2 rows and 4 columns\n",
    "tensor_4d = tf.constant([[[[1, 2, 5, 4], [3, 4, 1, 0]],\n",
    "                          [[5, 6, 2, 3], [7, 8, 6, 4]]]])\n",
    "# Print the 4D tensor\n",
    "print(f\"4D Tensor:\\n{tensor_4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor from tuple:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a tuple of tuples\n",
    "# The outer tuple contains inner tuples, each representing a row in the tensor\n",
    "tensor_a = tf.constant([(1, 2), (3, 4), (5, 6)])\n",
    "# Print the tensor created from the tuple\n",
    "print(f\"\\nTensor from tuple:\\n{tensor_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2b08f3 size=\"4.5\" face=\"Arial\"><b>3Ô∏è‚É£ Getting information from tensors</b></font><br/>\n",
    "‚ñ™ `shape` - what shape is the tensor? (some operations require specific shape rules)<br/>\n",
    "‚ñ™ `dtype` - what datatype are the elements within the tensor stored in?<br/>\n",
    "‚ñ™ `device` - what device is the tensor stored on? (usually GPU or CPU)<br/>\n",
    "\n",
    "**üî∏ Tensor datatypes**<br/>\n",
    "There are many different tensor datatypes available in TensorFlow. Some are specific for CPU and some are better for GPU. Generally, if you see `tf.device('/GPU:0')` anywhere, the tensor is being used for GPU (since NVIDIA GPUs use a computing toolkit called CUDA). The most common type (and generally the default) is `tf.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype: <dtype: 'float32'>, Device: /job:localhost/replica:0/task:0/device:CPU:0\n",
      "('tensor = <tf.Tensor: shape=(), dtype=float64, numpy=1.3333333333333333> --> '\n",
      " 'tensor.shape = TensorShape([]), tf.rank(tensor) = <tf.Tensor: shape=(), '\n",
      " 'dtype=int32, numpy=0>, tf.size(tensor) = <tf.Tensor: shape=(), dtype=int32, '\n",
      " 'numpy=1>')\n",
      "\n",
      "Float16 tensor: 1.3330078125\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with default dtype (float32) and print its dtype and device\n",
    "float_32_tensor = tf.constant([1.0, 5.0, 6.0])\n",
    "print(f\"Dtype: {float_32_tensor.dtype}, Device: {float_32_tensor.device}\")\n",
    "\n",
    "# Create a scalar tensor with explicit dtype (float64) and an empty shape (scalar)\n",
    "tensor = tf.constant(4/3, dtype=tf.float64, shape=())\n",
    "# Pretty-print tensor details: value, shape, rank, and size\n",
    "pprint.pprint(f\"{tensor = } --> {tensor.shape = }, {tf.rank(tensor) = }, {tf.size(tensor) = }\")\n",
    "\n",
    "# Change the dtype of the tensor from float64 to float16 using tf.cast\n",
    "tensor_float16 = tf.cast(tensor, tf.float16)\n",
    "# Print the new tensor with float16 dtype\n",
    "print(f\"\\nFloat16 tensor: {tensor_float16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f308ad size=\"4.5\" face=\"Arial\"><b>4Ô∏è‚É£ Math Operations</b></font><br/>\n",
    "‚ñ™ `Addition` ‚áí *a+b* or *tf.add(a, b)*<br/>\n",
    "‚ñ™ `Substraction` ‚áí *a-b* or *tf.subtract(a, b)*<br/>\n",
    "‚ñ™ `Multiplication (element-wise)` ‚áí *axb* or *tf.multiply(a, b)*<br/>\n",
    "‚ñ™ `Division` ‚áí *a/b* or *tf.divide(a, b)*<br/>\n",
    "‚ñ™ `Matrix multiplication` ‚áí *tf.matmul(a, b)*<br/>\n",
    "‚ñ™ `tf.reduce_mean & tf.math.reduce_std`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      "[[ 6  8]\n",
      " [10 12]]\n",
      "\n",
      "Subtraction:\n",
      "[[-4 -4]\n",
      " [-4 -4]]\n",
      "\n",
      "Element-wise Multiplication:\n",
      "[[ 5 12]\n",
      " [21 32]]\n",
      "\n",
      "Division:\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]]\n",
      "\n",
      "Matrix Multiplication:\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Define two 2x2 tensors 'a' and 'b'\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform element-wise addition\n",
    "add_result = a + b\n",
    "print(f\"Addition:\\n{add_result}\")\n",
    "\n",
    "# Perform element-wise subtraction\n",
    "sub_result = a - b\n",
    "print(f\"\\nSubtraction:\\n{sub_result}\")\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "mul_result = a * b\n",
    "print(f\"\\nElement-wise Multiplication:\\n{mul_result}\")\n",
    "\n",
    "# Perform element-wise division\n",
    "div_result = a / b\n",
    "print(f\"\\nDivision:\\n{div_result}\")\n",
    "\n",
    "# Perform matrix multiplication (dot product) using tf.matmul\n",
    "matmul_result = tf.matmul(a, b)\n",
    "print(f\"\\nMatrix Multiplication:\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean all: 2.5\n",
      "Mean dim 0: [2. 3.]\n",
      "Mean dim 1: [1.5 3.5]\n",
      "Std all: 1.1180340051651\n"
     ]
    }
   ],
   "source": [
    "# Define a 2x2 tensor with float values\n",
    "tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Calculate the mean of all elements in the tensor\n",
    "mean_all = tf.reduce_mean(tensor)\n",
    "\n",
    "# Calculate the mean along dimension 0 (columns)\n",
    "mean_dim0 = tf.reduce_mean(tensor, axis=0)\n",
    "\n",
    "# Calculate the mean along dimension 1 (rows)\n",
    "mean_dim1 = tf.reduce_mean(tensor, axis=1)\n",
    "# Print the mean values\n",
    "print(f\"Mean all: {mean_all}\")\n",
    "print(f\"Mean dim 0: {mean_dim0}\")\n",
    "print(f\"Mean dim 1: {mean_dim1}\")\n",
    "\n",
    "# Calculate the standard deviation of all elements in the tensor\n",
    "# Ensure the tensor is cast to float32 for compatibility with tf.math.reduce_std\n",
    "std_all = tf.math.reduce_std(tf.cast(tensor, tf.float32))\n",
    "# Print the standard deviation\n",
    "print(f\"Std all: {std_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#08e3f3 size=\"4.5\" face=\"Arial\"><b>5Ô∏è‚É£ Special Arrays</b></font><br/>\n",
    "‚ñ™ `ones`<br/>\n",
    "‚ñ™ `zeros`<br/>\n",
    "‚ñ™ `eye`<br/>\n",
    "‚ñ™ `fill`<br/>\n",
    "‚ñ™ `arange`<br/>\n",
    "‚ñ™ `reshape`<br/>\n",
    "‚ñ™ `linspace`<br/>\n",
    "\n",
    "üî∏ Using `tf.zeros_like(input)` or `tf.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:\n",
      "[[1.]\n",
      " [1.]]\n",
      "\n",
      "Zeros:\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "\n",
      "Eye:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "Full:\n",
      "[[2 2 2]\n",
      " [2 2 2]\n",
      " [2 2 2]\n",
      " [2 2 2]]\n",
      "\n",
      "Arange: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Reshaped:\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "Linspace: [0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of ones with shape [2, 1] (2 rows, 1 column)\n",
    "ones = tf.ones([2, 1])\n",
    "print(f\"Ones:\\n{ones}\")\n",
    "\n",
    "# Create a tensor of zeros with shape [3, 4, 3] (3 layers, 4 rows, 3 columns)\n",
    "zeros = tf.zeros([3, 4, 3])\n",
    "print(f\"\\nZeros:\\n{zeros}\")\n",
    "\n",
    "# Create an identity matrix (eye) with 5 rows and 4 columns\n",
    "eye = tf.eye(5, num_columns=4)\n",
    "print(f\"\\nEye:\\n{eye}\")\n",
    "\n",
    "# Create a tensor filled with the value 2 and shape [4, 3] (4 rows, 3 columns)\n",
    "full = tf.fill([4, 3], 2)\n",
    "print(f\"\\nFull:\\n{full}\")\n",
    "\n",
    "# Create a tensor with values from 0 to 9 (exclusive) using tf.range\n",
    "arange = tf.range(10)\n",
    "print(f\"\\nArange: {arange}\")\n",
    "\n",
    "# Reshape a tensor with values from 0 to 5 into a 2x3 matrix\n",
    "tensor = tf.range(6)\n",
    "reshaped = tf.reshape(tensor, [2, 3])\n",
    "print(f\"\\nReshaped:\\n{reshaped}\")\n",
    "\n",
    "# Create a tensor with 5 evenly spaced values between 0.0 and 1.0 using tf.linspace\n",
    "linspace = tf.linspace(0.0, 1.0, 5)\n",
    "print(f\"\\nLinspace: {linspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#98c007 size=\"4.5\" face=\"Arial\"><b>6Ô∏è‚É£ Random Arrays</b></font><br/>\n",
    "‚ñ™ `tf.random.uniform(shape, minval=0, maxval=1): or torch.randint` Create an n x m tensor filled with random numbers from a uniform distribution on the interval [0, 1).<br/>\n",
    "‚ñ™ `tf.random.normal(shape, mean=0, stddev=1): or torch.randn` Create an n x m tensor filled with random numbers from a normal distribution with mean 0 and variance 1.<br/>\n",
    "‚ñ™ `tf.random.uniform(shape, minval=low, maxval=high, dtype=tf.int32): or torch.rand` Create an n x m tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).<br/>\n",
    "‚ñ™ `tf.random.shuffle(value): or torch.randperm` Create a random permutation of integers from 0 to value.<br/>\n",
    "‚ñ™ `tf.transpose(input, perm): or torch.permute` Permute the original tensor to rearrange the axis order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Uniform:\n",
      "[[0.47720265 0.33357763 0.4960823 ]\n",
      " [0.48351312 0.2963959  0.69444907]\n",
      " [0.68488    0.6662284  0.07551682]\n",
      " [0.06608915 0.91428673 0.21982336]]\n",
      "\n",
      "Random Normal:\n",
      "[[-1.4789797  -0.29240268  0.07752764]\n",
      " [-0.5062714  -0.83865356 -0.09457338]\n",
      " [-1.52905    -0.6021644  -0.12325561]\n",
      " [ 0.10217136 -1.4168909   1.00783   ]]\n",
      "\n",
      "Random Int:\n",
      "[[ 9  8  6]\n",
      " [ 5  5 12]\n",
      " [ 6  2  7]\n",
      " [ 7  2  3]]\n",
      "\n",
      "Random Permutation: [3 6 5 7 9 2 4 8 0 1]\n",
      "\n",
      "Original shape: (224, 224, 3)\n",
      "\n",
      "Permuted shape: (3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "tf.random.set_seed(12)  # For reproducibility\n",
    "\n",
    "# Generate a 4x3 tensor with random uniform values between 0 and 1\n",
    "rand = tf.random.uniform([4, 3], minval=0, maxval=1)\n",
    "\n",
    "# Print the random uniform tensor\n",
    "print(f\"Random Uniform:\\n{rand}\")\n",
    "\n",
    "# Generate a 4x3 tensor with random values from a normal distribution (mean=0, stddev=1)\n",
    "randn = tf.random.normal([4, 3], mean=0, stddev=1)\n",
    "\n",
    "# Print the random normal tensor\n",
    "print(f\"\\nRandom Normal:\\n{randn}\")\n",
    "\n",
    "# Generate a 4x3 tensor with random integers between 2 and 12 (inclusive)\n",
    "randint = tf.random.uniform([4, 3], minval=2, maxval=13, dtype=tf.int32)\n",
    "\n",
    "# Print the random integer tensor\n",
    "print(f\"\\nRandom Int:\\n{randint}\")\n",
    "\n",
    "# Generate a random permutation of numbers from 0 to 9\n",
    "randperm = tf.random.shuffle(tf.range(10))\n",
    "\n",
    "# Print the random permutation\n",
    "print(f\"\\nRandom Permutation: {randperm}\")\n",
    "\n",
    "# Create a 224x224x3 tensor with random uniform values\n",
    "original = tf.random.uniform([224, 224, 3])\n",
    "\n",
    "# Transpose the tensor by permuting dimensions (from [224, 224, 3] to [3, 224, 224])\n",
    "permuted = tf.transpose(original, perm=[2, 0, 1])\n",
    "\n",
    "# Print the shape of the original tensor\n",
    "print(f\"\\nOriginal shape: {original.shape}\")\n",
    "\n",
    "# Print the shape of the permuted tensor\n",
    "print(f\"\\nPermuted shape: {permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#8a05b3 size=\"4.5\" face=\"Arial\"><b>7Ô∏è‚É£ Indexing & Slicing</b></font><br/>\n",
    "‚ñ™ `Indexing:` Use integer indices to specify the position of the element you want to retrieve (Accessing individual elements).<br/>\n",
    "‚ñ™ `Slicing:` Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator (Extracting sub-tensors).<br/>\n",
    "‚ñ™ `start:end` (exclusive end)<br/>\n",
    "‚ñ™ `start:` (from start to end of dimension)<br/>\n",
    "‚ñ™ `:end` (from beginning to end of dimension)<br/>\n",
    "‚ñ™ `:` (all elements)<br/>\n",
    "‚ñ™ `start:end:step` (start to end with given step)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[ 0.5615161  -0.06268908 -1.8762693  -0.4634338   1.5915105 ]\n",
      " [-0.28809077  0.42621186 -0.22641563  0.09014436  0.97549963]\n",
      " [ 1.0928404   1.4208329  -0.56682575 -0.27064663 -0.9919088 ]]\n",
      "\n",
      "a[0:2]:\n",
      "[[ 0.5615161  -0.06268908 -1.8762693  -0.4634338   1.5915105 ]\n",
      " [-0.28809077  0.42621186 -0.22641563  0.09014436  0.97549963]]\n",
      "\n",
      "a[::2, 2:]:\n",
      "[[-1.8762693  -0.4634338   1.5915105 ]\n",
      " [-0.56682575 -0.27064663 -0.9919088 ]]\n",
      "\n",
      "a_3d shape: (4, 6, 7)\n",
      "\n",
      "a_3d[1, 3:5, 2:4]:\n",
      "[[-1.0830227  0.9074694]\n",
      " [-1.5599444  1.4935122]]\n",
      "\n",
      "a_3d[:, :, -1]:\n",
      "[[ 0.5489658  -0.62722516  1.1423011  -1.6919721  -0.32114342  0.94501936]\n",
      " [-0.29095474 -0.93433493  0.16864355 -1.0387399   0.6346906   0.49951598]\n",
      " [-0.3861363  -0.70366967 -0.4324873  -0.58843803  0.5453059   0.39490286]\n",
      " [ 1.2849358   1.055529   -0.30219096 -0.04969664  0.71300924  0.58408606]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor with random values from a normal distribution (shape [3, 5])\n",
    "a = tf.random.normal([3, 5])\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "# Slice the first 2 rows of the tensor\n",
    "print(f\"\\na[0:2]:\\n{a[0:2]}\")\n",
    "\n",
    "# Slice every alternate row and columns starting from index 2\n",
    "print(f\"\\na[::2, 2:]:\\n{a[::2, 2:]}\")\n",
    "\n",
    "# Create a 3D tensor with random values from a normal distribution (shape [4, 6, 7])\n",
    "a_3d = tf.random.normal([4, 6, 7])\n",
    "print(f\"\\na_3d shape: {a_3d.shape}\")\n",
    "\n",
    "# Slice the tensor: take the 2nd layer (index 1), rows 3 to 4 (exclusive), and columns 2 to 3 (exclusive)\n",
    "print(f\"\\na_3d[1, 3:5, 2:4]:\\n{a_3d[1, 3:5, 2:4]}\")\n",
    "\n",
    "# Slice the tensor: take all layers, all rows, and the last column\n",
    "print(f\"\\na_3d[:, :, -1]:\\n{a_3d[:, :, -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f3084f size=\"4.5\" face=\"Arial\"><b>8Ô∏è‚É£ Unsqueeze & squeeze</b></font><br/>\n",
    "‚ñ™ The `tf.squeeze()` method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.<br/>\n",
    "‚ñ™ The `tf.expand_dims()` method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1, 3, 1, 4, 1)\n",
      "\n",
      "Squeezed shape: (3, 4)\n",
      "\n",
      "Original shape: (2, 1, 3, 1, 4)\n",
      "\n",
      "Squeeze dim 1: (2, 3, 1, 4)\n",
      "\n",
      "Original:\n",
      "[[-0.08559076  1.1976115 ]\n",
      " [ 0.38311407 -1.2576591 ]]\n",
      "\n",
      "Unsqueeze dim 0:\n",
      "[[[-0.08559076  1.1976115 ]\n",
      "  [ 0.38311407 -1.2576591 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with shape [1, 3, 1, 4, 1] and random normal values\n",
    "tensor_a = tf.random.normal([1, 3, 1, 4, 1])\n",
    "print(f\"Original shape: {tensor_a.shape}\")\n",
    "\n",
    "# Remove all dimensions of size 1 using tf.squeeze\n",
    "tensor_b = tf.squeeze(tensor_a)\n",
    "print(f\"\\nSqueezed shape: {tensor_b.shape}\")\n",
    "\n",
    "# Create another tensor with shape [2, 1, 3, 1, 4] and random normal values\n",
    "a = tf.random.normal([2, 1, 3, 1, 4])\n",
    "print(f\"\\nOriginal shape: {a.shape}\")\n",
    "\n",
    "# Remove only the dimension of size 1 at axis 1 using tf.squeeze\n",
    "print(f\"\\nSqueeze dim 1: {tf.squeeze(a, axis=1).shape}\")\n",
    "\n",
    "# Create a 2D tensor with shape [2, 2] and random normal values\n",
    "b = tf.random.normal([2, 2])\n",
    "print(f\"\\nOriginal:\\n{b}\")\n",
    "\n",
    "# Add a new dimension at axis 0 using tf.expand_dims\n",
    "print(f\"\\nUnsqueeze dim 0:\\n{tf.expand_dims(b, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#7ddbbf size=\"4.5\" face=\"Arial\"><b>9Ô∏è‚É£ TensorFlow Tensors & NumPy</b></font><br/>\n",
    "‚ñ™ `tf.convert_to_tensor(ndarray):` NumPy array ‚Üí TensorFlow tensor<br/>\n",
    "‚ñ™ `tf.Tensor.numpy():` TensorFlow tensor ‚Üí NumPy array<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1. 2. 3. 4. 5. 6. 7.]\n",
      "Tensor: [1. 2. 3. 4. 5. 6. 7.]\n",
      "NumPy from Tensor: [1. 2. 3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array with values from 1.0 to 7.0\n",
    "array = np.arange(1.0, 8.0)\n",
    "\n",
    "# Convert the NumPy array to a TensorFlow tensor\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "\n",
    "# Convert the TensorFlow tensor back to a NumPy array\n",
    "nump = tensor.numpy()\n",
    "\n",
    "# Print the original NumPy array\n",
    "print(f\"Array: {array}\")\n",
    "# Print the TensorFlow tensor\n",
    "print(f\"Tensor: {tensor}\")\n",
    "# Print the NumPy array converted from the TensorFlow tensor\n",
    "print(f\"NumPy from Tensor: {nump}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f0dc2d size=\"4.5\" face=\"Arial\"><b>üîü Array Manipulation</b></font><br/>\n",
    "‚ñ™ `tf.stack: or torch.stack` Stacks tensors along a new dimension.<br/>\n",
    "‚ñ™ `tf.concat or torch.cat:` Concatenates tensors along an existing dimension.<br/>\n",
    "‚ñ™ `tf.split or torch.split:` Dividing a tensor into multiple sub-arrays.<br/>\n",
    "‚ñ™ `tf.reshape or torch.flatten:` Compresses a tensor into a contiguous 1D representation.<br/>\n",
    "‚ñ™ `tf.identity or torch.clone:` Creates a deep copy. <br/>\n",
    "‚ñ™ `tf.tile or torch.repeat, torch.tile:` Repeats the tensor along specified dimensions. (Note: TensorFlow uses tf.tile for both repetition scenarios, unlike PyTorch's repeat and tile distinction.)<br/>\n",
    "‚ñ™ `tf.unique or torch.unique:` Finding unique elements in a tensor.<br/>\n",
    "‚ñ™ `tf.sort, tf.argsort or torch.sort, torch.argsort:` Returns both the sorted tensor and the indices of the sorted elements.<br/>\n",
    "‚ñ™ `tf.argmax, tf.argmin or torch.argmax, torch.argmin:` Finding the indices of the maximum and minimum values. For example, tf.argmax() and tf.argmin().<br/>\n",
    "‚ñ™ `tf.where(condition, x, y)`, `tf.args_where`, `tf.nonzero`, `extract(using arr[cond])` or `torch.where`, `torch.args_where:` Conditional operations. tf.where() returns elements based on a condition, tf.nonzero() returns indices of elements that satisfy a condition, and arr[cond] extracts elements based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked:\n",
      "[[[ 0.52072555  0.7971705 ]\n",
      "  [-0.8475972  -1.1279716 ]]\n",
      "\n",
      " [[ 0.85128456  0.7019337 ]\n",
      "  [-0.74072427  1.0812322 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Stack two tensors along a new axis (axis=0)\n",
    "a = tf.random.normal([2, 2])\n",
    "b = tf.random.normal([2, 2])\n",
    "\n",
    "stacked = tf.stack([a, b], axis=0)\n",
    "print(f\"Stacked:\\n{stacked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated:\n",
      "[[[ 0.52072555  0.7971705 ]\n",
      "  [-0.8475972  -1.1279716 ]\n",
      "  [ 0.85128456  0.7019337 ]\n",
      "  [-0.74072427  1.0812322 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate two tensors along an existing axis (axis=1)\n",
    "concatenated = tf.concat([tf.expand_dims(a, 0), tf.expand_dims(b, 0)], axis=1)\n",
    "print(f\"Concatenated:\\n{concatenated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:\n",
      "[<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[ 1,  2],\n",
      "       [ 5,  6],\n",
      "       [ 9, 10]], dtype=int32)>, <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[ 3,  4],\n",
      "       [ 7,  8],\n",
      "       [11, 12]], dtype=int32)>]\n"
     ]
    }
   ],
   "source": [
    "# Split a tensor into multiple tensors along a specified axis (axis=1)\n",
    "tensor = tf.range(1, 13)\n",
    "split_tensors = tf.split(tf.reshape(tensor, [3, 4]), num_or_size_splits=2, axis=1)\n",
    "print(f\"Split:\\n{split_tensors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_3d = <tf.Tensor: shape=(3, 2, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8]],\n",
      "\n",
      "       [[ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]],\n",
      "\n",
      "       [[17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]], dtype=int32)>\n",
      "Flattened:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# Flatten a 3D tensor into a 1D tensor\n",
    "a_3d = tf.reshape(tf.range(1, 25), [3, 2, 4])\n",
    "print(f'{a_3d = }')\n",
    "flattened = tf.reshape(a_3d, [-1])\n",
    "print(f\"Flattened:\\n{flattened}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloned:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a deep copy (clone) of a tensor using tf.identity\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "cloned = tf.identity(tensor)\n",
    "print(f\"Cloned:\\n{cloned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiled: [1 2 3 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Repeat (tile) a tensor along a specified axis\n",
    "tensor = tf.constant([1, 2, 3])\n",
    "tiled = tf.tile(tensor, [2])\n",
    "print(f\"Tiled: {tiled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: [2 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Find unique elements in a tensor\n",
    "tensor = tf.constant([2, 1, 3, 2, 1])\n",
    "unique_elements = tf.unique(tensor).y\n",
    "print(f\"Unique: {unique_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [1 1 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Sort the elements of a tensor\n",
    "sorted_tensor = tf.sort(tensor)\n",
    "print(f\"Sorted: {sorted_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argsort indices: [1 4 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Get the indices that would sort the tensor\n",
    "indices = tf.argsort(tensor)\n",
    "print(f\"Argsort indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argmax: [1 1 2 2], \n",
      "Argmin: [0 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the maximum and minimum value in the tensor\n",
    "max_idx = tf.argmax(tensor)\n",
    "min_idx = tf.argmin(tensor)\n",
    "print(f\"Argmax: {max_idx}, \\nArgmin: {min_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "[[  1   2   3   4]\n",
      " [  9   7  11 -20]\n",
      " [  9  -7  12   6]]\n",
      "\n",
      "Where:\n",
      "[[-10 -10   3   4]\n",
      " [  9   7 -10 -10]\n",
      " [  9 -10 -10   6]]\n"
     ]
    }
   ],
   "source": [
    "# Apply a conditional operation using tf.where\n",
    "tensor = tf.constant([[1, 2, 3, 4], [9, 7, 11, -20], [9, -7, 12, 6]])\n",
    "print(f\"tensor:\\n{tensor}\")\n",
    "\n",
    "result = tf.where((tensor >= 3) & (tensor < 10), tensor, -10)\n",
    "print(f\"\\nWhere:\\n{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
