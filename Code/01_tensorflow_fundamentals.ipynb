{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to Deep Learning with Keras and TensorFlow in Python**\n",
    "\n",
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**<br/>\n",
    "**[GitHub](https://github.com/RezaSaadatyar/Deep-Learning-in-python)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a framework for building and running machine learning models using tensors.<br/>\n",
    "A tensor generalizes vectors and matrices to higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base data types.<br/>\n",
    "\n",
    "‚ñ™ Command (run in terminal, not Python): `pip install tensorflow`<br/>\n",
    "‚ñ™ GPU version: `pip install tensorflow-gpu`<br/>\n",
    "\n",
    "**Outline:**<br/>\n",
    "‚ñ™ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)<br/>\n",
    "‚ñ™ Scalar, Vector, Column Vector, Matrix, & N-d Tensor<br/>\n",
    "‚ñ™ Getting information from tensors<br/>\n",
    "‚ñ™ Math Operations<br/>\n",
    "‚ñ™ Special Arrays<br/>\n",
    "‚ñ™ Random Arrays<br/>\n",
    "‚ñ™ Indexing & Slicing<br/>\n",
    "‚ñ™ Unsqueeze & squeeze<br/>\n",
    "‚ñ™ TensorFlow Tensors & NumPy<br/>\n",
    "‚ñ™ Array Manipulation<br/>\n",
    "‚ñ™ Eager Execution VS Graph Execution (@tf.function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'TensorFlow Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f3dc08 size=\"4.5\" face=\"Arial\"><b>1Ô∏è‚É£ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)</b></font><br/>\n",
    "`CPU:`<br/>\n",
    "‚ñ™ Designed for general-purpose computing.<br/>\n",
    "‚ñ™ Optimized for sequential tasks.<br/>\n",
    "‚ñ™ Has a few powerful cores.<br/>\n",
    "‚ñ™ Excellent at handling complex logic and single-threaded applications.<br/>\n",
    "  \n",
    "`GPU:`<br/>\n",
    "‚ñ™ Designed for parallel processing.<br/>\n",
    "‚ñ™ Has thousands of smaller, less powerful cores.<br/>\n",
    "‚ñ™ GPUs offer far faster numerical computing than CPUs.<br/>\n",
    "‚ñ™ Optimized for tasks that can be divided into many independent calculations.<br/>\n",
    "‚ñ™ Excellent for tasks like matrix operations, which are common in deep learning.<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means\n",
    "# \"run this on the command line\".\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      "Using device: /CPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability by listing physical devices and checking if any GPU is present\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU') != []}\")\n",
    "# Example output: GPU Available: False (if no GPU is detected)\n",
    "\n",
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "# Print the device being used for computation\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#08f308 size=\"4.5\" face=\"Arial\"><b>2Ô∏è‚É£ Scalar, Vector, Column Vector, Matrix, & N-d Tensor</b></font><br/>\n",
    "A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.<br/>\n",
    "‚ñ™ `0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.<br/>\n",
    "‚ñ™ `1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "‚ñ™ `2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.<br/>\n",
    "‚ñ™ `3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 1.3333333730697632\n"
     ]
    }
   ],
   "source": [
    "# Create a scalar (0-dimensional tensor) with a constant value of 4/3 and specify its data type as float32\n",
    "scalar = tf.constant(4/3, dtype=tf.float32)\n",
    "# Print the scalar tensor\n",
    "print(f\"Scalar: {scalar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [1 2 3] --> vector.__class__ = <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Column Vector:\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "# Create a vector (1-dimensional tensor) with a list of values [1, 2, 3]\n",
    "vector = tf.constant([1, 2, 3])\n",
    "# Print the vector tensor and its class type\n",
    "print(f\"Vector: {vector} --> {vector.__class__ = }\")\n",
    "\n",
    "# Create a column vector (2-dimensional tensor) with a nested list of values [[1], [2], [3], [4]]\n",
    "col_vector = tf.constant([[1], [2], [3], [4]])\n",
    "# Print the column vector tensor\n",
    "print(f\"Column Vector:\\n{col_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix (2-dimensional tensor) with a nested list of values [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "# Print the matrix tensor\n",
    "print(f\"Matrix:\\n{matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Tensor:\n",
      "[[[1 2 2 5]\n",
      "  [3 4 0 8]]\n",
      "\n",
      " [[5 6 6 7]\n",
      "  [4 8 1 2]]\n",
      "\n",
      " [[1 1 8 9]\n",
      "  [0 0 2 3]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor (3-dimensional tensor) with a nested list of values\n",
    "# The structure is: 3 layers, each containing 2 rows and 4 columns\n",
    "tensor_3d = tf.constant([[[1, 2, 2, 5], [3, 4, 0, 8]],\n",
    "                         [[5, 6, 6, 7], [4, 8, 1, 2]],\n",
    "                         [[1, 1, 8, 9], [0, 0, 2, 3]]])\n",
    "# Print the 3D tensor\n",
    "print(f\"3D Tensor:\\n{tensor_3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4D Tensor:\n",
      "[[[[1 2 5 4]\n",
      "   [3 4 1 0]]\n",
      "\n",
      "  [[5 6 2 3]\n",
      "   [7 8 6 4]]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 4D tensor (4-dimensional tensor) with a deeply nested list of values\n",
    "# The structure is: 1 batch, 2 layers, each containing 2 rows and 4 columns\n",
    "tensor_4d = tf.constant([[[[1, 2, 5, 4], [3, 4, 1, 0]],\n",
    "                          [[5, 6, 2, 3], [7, 8, 6, 4]]]])\n",
    "# Print the 4D tensor\n",
    "print(f\"4D Tensor:\\n{tensor_4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor from tuple:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a tuple of tuples\n",
    "# The outer tuple contains inner tuples, each representing a row in the tensor\n",
    "tensor_a = tf.constant([(1, 2), (3, 4), (5, 6)])\n",
    "# Print the tensor created from the tuple\n",
    "print(f\"\\nTensor from tuple:\\n{tensor_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2b08f3 size=\"4.5\" face=\"Arial\"><b>3Ô∏è‚É£ Getting information from tensors</b></font><br/>\n",
    "‚ñ™ `shape` - what shape is the tensor? (some operations require specific shape rules)<br/>\n",
    "‚ñ™ `dtype` - what datatype are the elements within the tensor stored in?<br/>\n",
    "‚ñ™ `device` - what device is the tensor stored on? (usually GPU or CPU)<br/>\n",
    "\n",
    "**üî∏ Tensor datatypes**<br/>\n",
    "There are many different tensor datatypes available in TensorFlow. Some are specific for CPU and some are better for GPU. Generally, if you see `tf.device('/GPU:0')` anywhere, the tensor is being used for GPU (since NVIDIA GPUs use a computing toolkit called CUDA). The most common type (and generally the default) is `tf.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype: <dtype: 'float32'>, Device: /job:localhost/replica:0/task:0/device:CPU:0\n",
      "('tensor = <tf.Tensor: shape=(), dtype=float64, numpy=1.3333333333333333> --> '\n",
      " 'tensor.shape = TensorShape([]), tf.rank(tensor) = <tf.Tensor: shape=(), '\n",
      " 'dtype=int32, numpy=0>, tf.size(tensor) = <tf.Tensor: shape=(), dtype=int32, '\n",
      " 'numpy=1>')\n",
      "\n",
      "Float16 tensor: 1.3330078125\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with default dtype (float32) and print its dtype and device\n",
    "float_32_tensor = tf.constant([1.0, 5.0, 6.0])\n",
    "print(f\"Dtype: {float_32_tensor.dtype}, Device: {float_32_tensor.device}\")\n",
    "\n",
    "# Create a scalar tensor with explicit dtype (float64) and an empty shape (scalar)\n",
    "tensor = tf.constant(4/3, dtype=tf.float64, shape=())\n",
    "# Pretty-print tensor details: value, shape, rank, and size\n",
    "pprint.pprint(f\"{tensor = } --> {tensor.shape = }, {tf.rank(tensor) = }, {tf.size(tensor) = }\")\n",
    "\n",
    "# Change the dtype of the tensor from float64 to float16 using tf.cast\n",
    "tensor_float16 = tf.cast(tensor, tf.float16)\n",
    "# Print the new tensor with float16 dtype\n",
    "print(f\"\\nFloat16 tensor: {tensor_float16}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f308ad size=\"4.5\" face=\"Arial\"><b>4Ô∏è‚É£ Math Operations</b></font><br/>\n",
    "‚ñ™ `Addition` ‚áí *a+b* or *tf.add(a, b)*<br/>\n",
    "‚ñ™ `Substraction` ‚áí *a-b* or *tf.subtract(a, b)*<br/>\n",
    "‚ñ™ `Multiplication (element-wise)` ‚áí *axb* or *tf.multiply(a, b)*<br/>\n",
    "‚ñ™ `Division` ‚áí *a/b* or *tf.divide(a, b)*<br/>\n",
    "‚ñ™ `Matrix multiplication` ‚áí *tf.matmul(a, b)*<br/>\n",
    "‚ñ™ `tf.reduce_mean & tf.math.reduce_std`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      "[[ 6  8]\n",
      " [10 12]]\n",
      "\n",
      "Subtraction:\n",
      "[[-4 -4]\n",
      " [-4 -4]]\n",
      "\n",
      "Element-wise Multiplication:\n",
      "[[ 5 12]\n",
      " [21 32]]\n",
      "\n",
      "Division:\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]]\n",
      "\n",
      "Matrix Multiplication:\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Define two 2x2 tensors 'a' and 'b'\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "b = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform element-wise addition\n",
    "add_result = a + b\n",
    "print(f\"Addition:\\n{add_result}\")\n",
    "\n",
    "# Perform element-wise subtraction\n",
    "sub_result = a - b\n",
    "print(f\"\\nSubtraction:\\n{sub_result}\")\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "mul_result = a * b\n",
    "print(f\"\\nElement-wise Multiplication:\\n{mul_result}\")\n",
    "\n",
    "# Perform element-wise division\n",
    "div_result = a / b\n",
    "print(f\"\\nDivision:\\n{div_result}\")\n",
    "\n",
    "# Perform matrix multiplication (dot product) using tf.matmul\n",
    "matmul_result = tf.matmul(a, b)\n",
    "print(f\"\\nMatrix Multiplication:\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean all: 2.5\n",
      "Mean dim 0: [2. 3.]\n",
      "Mean dim 1: [1.5 3.5]\n",
      "Std all: 1.1180340051651\n"
     ]
    }
   ],
   "source": [
    "# Define a 2x2 tensor with float values\n",
    "tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Calculate the mean of all elements in the tensor\n",
    "mean_all = tf.reduce_mean(tensor)\n",
    "\n",
    "# Calculate the mean along dimension 0 (columns)\n",
    "mean_dim0 = tf.reduce_mean(tensor, axis=0)\n",
    "\n",
    "# Calculate the mean along dimension 1 (rows)\n",
    "mean_dim1 = tf.reduce_mean(tensor, axis=1)\n",
    "# Print the mean values\n",
    "print(f\"Mean all: {mean_all}\")\n",
    "print(f\"Mean dim 0: {mean_dim0}\")\n",
    "print(f\"Mean dim 1: {mean_dim1}\")\n",
    "\n",
    "# Calculate the standard deviation of all elements in the tensor\n",
    "# Ensure the tensor is cast to float32 for compatibility with tf.math.reduce_std\n",
    "std_all = tf.math.reduce_std(tf.cast(tensor, tf.float32))\n",
    "# Print the standard deviation\n",
    "print(f\"Std all: {std_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#08e3f3 size=\"4.5\" face=\"Arial\"><b>5Ô∏è‚É£ Special Arrays</b></font><br/>\n",
    "‚ñ™ `ones`<br/>\n",
    "‚ñ™ `zeros`<br/>\n",
    "‚ñ™ `eye`<br/>\n",
    "‚ñ™ `fill`<br/>\n",
    "‚ñ™ `arange`<br/>\n",
    "‚ñ™ `reshape`<br/>\n",
    "‚ñ™ `linspace`<br/>\n",
    "\n",
    "üî∏ Using `tf.zeros_like(input)` or `tf.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:\n",
      "[[1.]\n",
      " [1.]]\n",
      "\n",
      "Zeros:\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "\n",
      "Eye:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "Full:\n",
      "[[2 2 2]\n",
      " [2 2 2]\n",
      " [2 2 2]\n",
      " [2 2 2]]\n",
      "\n",
      "Arange: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Reshaped:\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "Linspace: [0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of ones with shape [2, 1] (2 rows, 1 column)\n",
    "ones = tf.ones([2, 1])\n",
    "print(f\"Ones:\\n{ones}\")\n",
    "\n",
    "# Create a tensor of zeros with shape [3, 4, 3] (3 layers, 4 rows, 3 columns)\n",
    "zeros = tf.zeros([3, 4, 3])\n",
    "print(f\"\\nZeros:\\n{zeros}\")\n",
    "\n",
    "# Create an identity matrix (eye) with 5 rows and 4 columns\n",
    "eye = tf.eye(5, num_columns=4)\n",
    "print(f\"\\nEye:\\n{eye}\")\n",
    "\n",
    "# Create a tensor filled with the value 2 and shape [4, 3] (4 rows, 3 columns)\n",
    "full = tf.fill([4, 3], 2)\n",
    "print(f\"\\nFull:\\n{full}\")\n",
    "\n",
    "# Create a tensor with values from 0 to 9 (exclusive) using tf.range\n",
    "arange = tf.range(10)\n",
    "print(f\"\\nArange: {arange}\")\n",
    "\n",
    "# Reshape a tensor with values from 0 to 5 into a 2x3 matrix\n",
    "tensor = tf.range(6)\n",
    "reshaped = tf.reshape(tensor, [2, 3])\n",
    "print(f\"\\nReshaped:\\n{reshaped}\")\n",
    "\n",
    "# Create a tensor with 5 evenly spaced values between 0.0 and 1.0 using tf.linspace\n",
    "linspace = tf.linspace(0.0, 1.0, 5)\n",
    "print(f\"\\nLinspace: {linspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#98c007 size=\"4.5\" face=\"Arial\"><b>6Ô∏è‚É£ Random Arrays</b></font><br/>\n",
    "‚ñ™ `tf.random.uniform(shape, minval=0, maxval=1): or torch.randint` Create an n x m tensor filled with random numbers from a uniform distribution on the interval [0, 1).<br/>\n",
    "‚ñ™ `tf.random.normal(shape, mean=0, stddev=1): or torch.randn` Create an n x m tensor filled with random numbers from a normal distribution with mean 0 and variance 1.<br/>\n",
    "‚ñ™ `tf.random.uniform(shape, minval=low, maxval=high, dtype=tf.int32): or torch.rand` Create an n x m tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).<br/>\n",
    "‚ñ™ `tf.random.shuffle(value): or torch.randperm` Create a random permutation of integers from 0 to value.<br/>\n",
    "‚ñ™ `tf.transpose(input, perm): or torch.permute` Permute the original tensor to rearrange the axis order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Uniform:\n",
      "[[0.47720265 0.33357763 0.4960823 ]\n",
      " [0.48351312 0.2963959  0.69444907]\n",
      " [0.68488    0.6662284  0.07551682]\n",
      " [0.06608915 0.91428673 0.21982336]]\n",
      "\n",
      "Random Normal:\n",
      "[[-1.4789797  -0.29240268  0.07752764]\n",
      " [-0.5062714  -0.83865356 -0.09457338]\n",
      " [-1.52905    -0.6021644  -0.12325561]\n",
      " [ 0.10217136 -1.4168909   1.00783   ]]\n",
      "\n",
      "Random Int:\n",
      "[[ 9  8  6]\n",
      " [ 5  5 12]\n",
      " [ 6  2  7]\n",
      " [ 7  2  3]]\n",
      "\n",
      "Random Permutation: [3 6 5 7 9 2 4 8 0 1]\n",
      "\n",
      "Original shape: (224, 224, 3)\n",
      "\n",
      "Permuted shape: (3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "tf.random.set_seed(12)  # For reproducibility\n",
    "\n",
    "# Generate a 4x3 tensor with random uniform values between 0 and 1\n",
    "rand = tf.random.uniform([4, 3], minval=0, maxval=1)\n",
    "\n",
    "# Print the random uniform tensor\n",
    "print(f\"Random Uniform:\\n{rand}\")\n",
    "\n",
    "# Generate a 4x3 tensor with random values from a normal distribution (mean=0, stddev=1)\n",
    "randn = tf.random.normal([4, 3], mean=0, stddev=1)\n",
    "\n",
    "# Print the random normal tensor\n",
    "print(f\"\\nRandom Normal:\\n{randn}\")\n",
    "\n",
    "# Generate a 4x3 tensor with random integers between 2 and 12 (inclusive)\n",
    "randint = tf.random.uniform([4, 3], minval=2, maxval=13, dtype=tf.int32)\n",
    "\n",
    "# Print the random integer tensor\n",
    "print(f\"\\nRandom Int:\\n{randint}\")\n",
    "\n",
    "# Generate a random permutation of numbers from 0 to 9\n",
    "randperm = tf.random.shuffle(tf.range(10))\n",
    "\n",
    "# Print the random permutation\n",
    "print(f\"\\nRandom Permutation: {randperm}\")\n",
    "\n",
    "# Create a 224x224x3 tensor with random uniform values\n",
    "original = tf.random.uniform([224, 224, 3])\n",
    "\n",
    "# Transpose the tensor by permuting dimensions (from [224, 224, 3] to [3, 224, 224])\n",
    "permuted = tf.transpose(original, perm=[2, 0, 1])\n",
    "\n",
    "# Print the shape of the original tensor\n",
    "print(f\"\\nOriginal shape: {original.shape}\")\n",
    "\n",
    "# Print the shape of the permuted tensor\n",
    "print(f\"\\nPermuted shape: {permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#8a05b3 size=\"4.5\" face=\"Arial\"><b>7Ô∏è‚É£ Indexing & Slicing</b></font><br/>\n",
    "‚ñ™ `Indexing:` Use integer indices to specify the position of the element you want to retrieve (Accessing individual elements).<br/>\n",
    "‚ñ™ `Slicing:` Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator (Extracting sub-tensors).<br/>\n",
    "‚ñ™ `start:end` (exclusive end)<br/>\n",
    "‚ñ™ `start:` (from start to end of dimension)<br/>\n",
    "‚ñ™ `:end` (from beginning to end of dimension)<br/>\n",
    "‚ñ™ `:` (all elements)<br/>\n",
    "‚ñ™ `start:end:step` (start to end with given step)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[[ 1.0156628   3.0590162   0.07443837 -1.2894605  -0.4968059 ]\n",
      " [ 0.61609566 -1.5842187   0.11161456 -1.5933702  -0.06296134]\n",
      " [-0.5211277   1.0874045  -0.1551225   0.14448617  0.6372794 ]]\n",
      "\n",
      "a[0:2]:\n",
      "[[ 1.0156628   3.0590162   0.07443837 -1.2894605  -0.4968059 ]\n",
      " [ 0.61609566 -1.5842187   0.11161456 -1.5933702  -0.06296134]]\n",
      "\n",
      "a[::2, 2:]:\n",
      "[[ 0.07443837 -1.2894605  -0.4968059 ]\n",
      " [-0.1551225   0.14448617  0.6372794 ]]\n",
      "\n",
      "a_3d shape: (4, 6, 7)\n",
      "\n",
      "a_3d[1, 3:5, 2:4]:\n",
      "[[-0.12273395 -0.27381593]\n",
      " [-1.141361    0.2504069 ]]\n",
      "\n",
      "a_3d[:, :, -1]:\n",
      "[[-1.2023895   0.16818506  0.72566223 -1.7238864  -0.99754405  0.07919075]\n",
      " [-1.2934966  -1.002199    0.21651204  0.87707484 -1.6703687   0.29637307]\n",
      " [ 0.7626682   0.33879367 -0.3415173  -0.99739355 -0.7057182   0.7534898 ]\n",
      " [ 0.06815628 -0.5789059   0.7776215  -0.39729667 -0.03448901 -0.48328176]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor with random values from a normal distribution (shape [3, 5])\n",
    "a = tf.random.normal([3, 5])\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "# Slice the first 2 rows of the tensor using Python slicing syntax\n",
    "print(f\"\\na[0:2]:\\n{a[0:2]}\")\n",
    "\n",
    "# Slice every alternate row and columns starting from index 2 using Python slicing syntax\n",
    "print(f\"\\na[::2, 2:]:\\n{a[::2, 2:]}\")\n",
    "\n",
    "# Create a 3D tensor with random values from a normal distribution (shape [4, 6, 7])\n",
    "a_3d = tf.random.normal([4, 6, 7])\n",
    "print(f\"\\na_3d shape: {a_3d.shape}\")\n",
    "\n",
    "# Slice the tensor: take the 2nd layer (index 1), rows 3 to 4 (exclusive), and columns 2 to 3 (exclusive)\n",
    "print(f\"\\na_3d[1, 3:5, 2:4]:\\n{a_3d[1, 3:5, 2:4]}\")\n",
    "\n",
    "# Slice the tensor: take all layers, all rows, and the last column using Python slicing syntax\n",
    "print(f\"\\na_3d[:, :, -1]:\\n{a_3d[:, :, -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f3084f size=\"4.5\" face=\"Arial\"><b>8Ô∏è‚É£ Unsqueeze & squeeze</b></font><br/>\n",
    "‚ñ™ The `tf.squeeze()` method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.<br/>\n",
    "‚ñ™ The `tf.expand_dims()` method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1, 3, 1, 4, 1)\n",
      "\n",
      "Squeezed shape: (3, 4)\n",
      "\n",
      "Original shape: (2, 1, 3, 1, 4)\n",
      "\n",
      "Squeeze dim 1: (2, 3, 1, 4)\n",
      "\n",
      "Original:\n",
      "[[ 1.4327698   0.33727238]\n",
      " [-0.38687673  1.5118667 ]]\n",
      "\n",
      "Unsqueeze dim 0:\n",
      "[[[ 1.4327698   0.33727238]\n",
      "  [-0.38687673  1.5118667 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with shape [1, 3, 1, 4, 1] and random normal values\n",
    "tensor_a = tf.random.normal([1, 3, 1, 4, 1])\n",
    "print(f\"Original shape: {tensor_a.shape}\")\n",
    "\n",
    "# Remove all dimensions of size 1 using tf.squeeze\n",
    "tensor_b = tf.squeeze(tensor_a)\n",
    "print(f\"\\nSqueezed shape: {tensor_b.shape}\")\n",
    "\n",
    "# Create another tensor with shape [2, 1, 3, 1, 4] and random normal values\n",
    "a = tf.random.normal([2, 1, 3, 1, 4])\n",
    "print(f\"\\nOriginal shape: {a.shape}\")\n",
    "\n",
    "# Remove only the dimension of size 1 at axis 1 using tf.squeeze\n",
    "print(f\"\\nSqueeze dim 1: {tf.squeeze(a, axis=1).shape}\")\n",
    "\n",
    "# Create a 2D tensor with shape [2, 2] and random normal values\n",
    "b = tf.random.normal([2, 2])\n",
    "print(f\"\\nOriginal:\\n{b}\")\n",
    "\n",
    "# Add a new dimension at axis 0 using tf.expand_dims\n",
    "print(f\"\\nUnsqueeze dim 0:\\n{tf.expand_dims(b, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#7ddbbf size=\"4.5\" face=\"Arial\"><b>9Ô∏è‚É£ TensorFlow Tensors & NumPy</b></font><br/>\n",
    "‚ñ™ `tf.convert_to_tensor(ndarray):` NumPy array ‚Üí TensorFlow tensor<br/>\n",
    "‚ñ™ `tf.Tensor.numpy():` TensorFlow tensor ‚Üí NumPy array<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1. 2. 3. 4. 5. 6. 7.]\n",
      "Tensor: [1. 2. 3. 4. 5. 6. 7.]\n",
      "NumPy from Tensor: [1. 2. 3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array with values from 1.0 to 7.0 using np.arange\n",
    "array = np.arange(1.0, 8.0)\n",
    "\n",
    "# Convert the NumPy array to a TensorFlow tensor using tf.convert_to_tensor\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "\n",
    "# Convert the TensorFlow tensor back to a NumPy array using the .numpy() method\n",
    "nump = tensor.numpy()\n",
    "\n",
    "# Print the original NumPy array\n",
    "print(f\"Array: {array}\")\n",
    "# Print the TensorFlow tensor\n",
    "print(f\"Tensor: {tensor}\")\n",
    "# Print the NumPy array converted from the TensorFlow tensor\n",
    "print(f\"NumPy from Tensor: {nump}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#f0dc2d size=\"4.5\" face=\"Arial\"><b>üîü Array Manipulation</b></font><br/>\n",
    "‚ñ™ `tf.stack: or torch.stack` Stacks tensors along a new dimension.<br/>\n",
    "‚ñ™ `tf.concat or torch.cat:` Concatenates tensors along an existing dimension.<br/>\n",
    "‚ñ™ `tf.split or torch.split:` Dividing a tensor into multiple sub-arrays.<br/>\n",
    "‚ñ™ `tf.reshape or torch.flatten:` Compresses a tensor into a contiguous 1D representation.<br/>\n",
    "‚ñ™ `tf.identity or torch.clone:` Creates a deep copy. <br/>\n",
    "‚ñ™ `tf.tile or torch.repeat, torch.tile:` Repeats the tensor along specified dimensions. (Note: TensorFlow uses tf.tile for both repetition scenarios, unlike PyTorch's repeat and tile distinction.)<br/>\n",
    "‚ñ™ `tf.unique or torch.unique:` Finding unique elements in a tensor.<br/>\n",
    "‚ñ™ `tf.sort, tf.argsort or torch.sort, torch.argsort:` Returns both the sorted tensor and the indices of the sorted elements.<br/>\n",
    "‚ñ™ `tf.argmax, tf.argmin or torch.argmax, torch.argmin:` Finding the indices of the maximum and minimum values. For example, tf.argmax() and tf.argmin().<br/>\n",
    "‚ñ™ `tf.where(condition, x, y)`, `tf.args_where`, `tf.nonzero`, `extract(using arr[cond])` or `torch.where`, `torch.args_where:` Conditional operations. tf.where() returns elements based on a condition, tf.nonzero() returns indices of elements that satisfy a condition, and arr[cond] extracts elements based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked:\n",
      "[[[-1.2241553   0.74886197]\n",
      "  [ 0.1875941   2.4983573 ]]\n",
      "\n",
      " [[ 1.2057035  -0.07163852]\n",
      "  [ 0.9780721   2.2133744 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Create two random normal tensors with shape [2, 2]\n",
    "a = tf.random.normal([2, 2])\n",
    "b = tf.random.normal([2, 2])\n",
    "\n",
    "# Stack the two tensors along a new axis (axis=0)\n",
    "# The `tf.stack` function combines the tensors along a new dimension at the specified axis\n",
    "stacked = tf.stack([a, b], axis=0)\n",
    "\n",
    "# Print the stacked tensor\n",
    "print(f\"Stacked:\\n{stacked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated:\n",
      "[[[-1.2241553   0.74886197]\n",
      "  [ 0.1875941   2.4983573 ]\n",
      "  [ 1.2057035  -0.07163852]\n",
      "  [ 0.9780721   2.2133744 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate two tensors along an existing axis (axis=1)\n",
    "# First, expand the dimensions of tensors `a` and `b` to make them compatible for concatenation\n",
    "# The `tf.expand_dims` function adds a new dimension at the specified axis (axis=0 here)\n",
    "# Then, concatenate the expanded tensors along axis=1\n",
    "concatenated = tf.concat([tf.expand_dims(a, 0), tf.expand_dims(b, 0)], axis=1)\n",
    "\n",
    "# Print the concatenated tensor\n",
    "print(f\"Concatenated:\\n{concatenated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:\n",
      "[<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[ 1,  2],\n",
      "       [ 5,  6],\n",
      "       [ 9, 10]], dtype=int32)>, <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "array([[ 3,  4],\n",
      "       [ 7,  8],\n",
      "       [11, 12]], dtype=int32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a 1D tensor using tf.range with values from 1 to 12\n",
    "tensor = tf.range(1, 13)\n",
    "\n",
    "# Reshape the 1D tensor into a 2D tensor with shape [3, 4]\n",
    "reshaped_tensor = tf.reshape(tensor, [3, 4])\n",
    "\n",
    "# Split the reshaped tensor into multiple tensors along the specified axis (axis=1)\n",
    "# The `num_or_size_splits=2` argument splits the tensor into 2 equal parts along axis 1\n",
    "split_tensors = tf.split(reshaped_tensor, num_or_size_splits=2, axis=1)\n",
    "\n",
    "# Print the split tensors\n",
    "print(f\"Split:\\n{split_tensors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_3d = <tf.Tensor: shape=(3, 2, 4), dtype=int32, numpy=\n",
      "array([[[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8]],\n",
      "\n",
      "       [[ 9, 10, 11, 12],\n",
      "        [13, 14, 15, 16]],\n",
      "\n",
      "       [[17, 18, 19, 20],\n",
      "        [21, 22, 23, 24]]], dtype=int32)>\n",
      "Flattened:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor using tf.reshape and tf.range\n",
    "# The tensor is reshaped to have dimensions [3, 2, 4] and contains values from 1 to 24\n",
    "a_3d = tf.reshape(tf.range(1, 25), [3, 2, 4])\n",
    "\n",
    "# Print the original 3D tensor\n",
    "print(f'{a_3d = }')\n",
    "\n",
    "# Flatten the 3D tensor into a 1D tensor using tf.reshape\n",
    "# The `-1` in the reshape operation automatically computes the size of the 1D tensor\n",
    "flattened = tf.reshape(a_3d, [-1])\n",
    "\n",
    "# Print the flattened 1D tensor\n",
    "print(f\"Flattened:\\n{flattened}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloned:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Create a deep copy (clone) of the tensor using tf.identity\n",
    "# The `tf.identity` function creates a new tensor with the same content as the input tensor.\n",
    "cloned = tf.identity(tensor)\n",
    "\n",
    "# Print the cloned tensor\n",
    "print(f\"Cloned:\\n{cloned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiled: [1 2 3 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "tensor = tf.constant([1, 2, 3])\n",
    "\n",
    "# Repeat (tile) the tensor along a specified axis\n",
    "# The `tf.tile` function repeats the input tensor according to the multiples specified.\n",
    "# Here, the tensor is repeated 2 times along the first axis.\n",
    "tiled = tf.tile(tensor, [2])\n",
    "\n",
    "# Print the tiled tensor\n",
    "print(f\"Tiled: {tiled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: [2 1 3]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "# The tensor is a 1D array with values [2, 1, 3, 2, 1]\n",
    "tensor = tf.constant([2, 1, 3, 2, 1])\n",
    "\n",
    "# Find the unique elements in the tensor\n",
    "# tf.unique returns a named tuple with two fields:\n",
    "#   - `y`: A tensor containing the unique elements.\n",
    "#   - `idx`: A tensor containing the indices of the unique elements in the original tensor.\n",
    "unique_elements = tf.unique(tensor).y\n",
    "\n",
    "# Print the unique elements\n",
    "print(f\"Unique: {unique_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [[  1   2   3   4]\n",
      " [-20   7   9  11]\n",
      " [ -7   6   9  12]]\n",
      "Argsort indices: [[0 1 2 3]\n",
      " [3 1 0 2]\n",
      " [1 3 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "# The tensor is a 2D array with shape (3, 4)\n",
    "tensor = tf.constant([[1, 2, 3, 4], [9, 7, 11, -20], [9, -7, 12, 6]])\n",
    "\n",
    "# Sort the elements of the tensor along the last axis (default is axis=-1)\n",
    "# The result is a tensor with the same shape as the input, but with elements sorted in ascending order.\n",
    "sorted_tensor = tf.sort(tensor)\n",
    "\n",
    "# Print the sorted tensor\n",
    "print(f\"Sorted: {sorted_tensor}\")\n",
    "\n",
    "# Get the indices that would sort the tensor along the last axis (default is axis=-1)\n",
    "# The result is a tensor of indices that can be used to rearrange the original tensor into sorted order.\n",
    "indices = tf.argsort(tensor)\n",
    "\n",
    "# Print the indices that would sort the tensor\n",
    "print(f\"Argsort indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted: [1 1 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "# The tensor is a 2D array with shape (3, 4)\n",
    "tensor = tf.constant([[1, 2, 3, 4], [9, 7, 11, -20], [9, -7, 12, 6]])\n",
    "\n",
    "# Find the index of the maximum value in the tensor\n",
    "# tf.argmax returns the index of the maximum value along a specified axis.\n",
    "# By default, it operates along the first axis (axis=0), which means it finds the maximum value for each column.\n",
    "max_idx = tf.argmax(tensor)\n",
    "\n",
    "# Find the index of the minimum value in the tensor\n",
    "# tf.argmin returns the index of the minimum value along a specified axis.\n",
    "# By default, it operates along the first axis (axis=0), which means it finds the minimum value for each column.\n",
    "min_idx = tf.argmin(tensor)\n",
    "\n",
    "# Print the indices of the maximum and minimum values\n",
    "print(f\"Argmax: {max_idx}, \\nArgmin: {min_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "[[  1   2   3   4]\n",
      " [  9   7  11 -20]\n",
      " [  9  -7  12   6]]\n",
      "\n",
      "Where:\n",
      "[[-10 -10   3   4]\n",
      " [  9   7 -10 -10]\n",
      " [  9 -10 -10   6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow constant tensor with the given values\n",
    "# The tensor is a 2D array with shape (3, 4)\n",
    "tensor = tf.constant([[1, 2, 3, 4], [9, 7, 11, -20], [9, -7, 12, 6]])\n",
    "\n",
    "# Print the original tensor\n",
    "print(f\"tensor:\\n{tensor}\")\n",
    "\n",
    "# Apply a conditional operation using tf.where\n",
    "# The condition is: (tensor >= 3) & (tensor < 10)\n",
    "# If the condition is true, keep the original value from `tensor`.\n",
    "# If the condition is false, replace the value with -10.\n",
    "result = tf.where((tensor >= 3) & (tensor < 10), tensor, -10)\n",
    "\n",
    "# Print the result of the tf.where operation\n",
    "print(f\"\\nWhere:\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#336600 size=\"4.5\" face=\"Arial\"><b> [Eager Execution VS Graph Execution (@tf.function)](https://www.tensorflow.org/guide/intro_to_graphs)</b></font><br/>\n",
    "[tensorflow eager execution vs graph](https://jonathan-hui.medium.com/tensorflow-eager-execution-v-s-graph-tf-function-6edaa870b1f1)<br/>\n",
    "\n",
    "In TensorFlow, code can be executed in two primary modes: `Eager Execution` and `Graph Execution`. These modes determine how operations are processed and optimized, which can impact performance, debugging, and deployment.<br/>\n",
    "\n",
    "**Eager Execution** in TensorFlow 2.x is an imperative mode where operations execute instantly without a computational graph, offering an interactive, Python-like coding experience. Eager execution is enabled by default.<br/>\n",
    "\n",
    "`Advantages:`<br/>\n",
    "‚ñ™ Simplifies debugging with tools like print() or a debugger.<br/> \n",
    "‚ñ™ Great for rapid prototyping and experimentation.<br/>\n",
    "‚ñ™ Eliminates the need to build graphs or sessions manually.<br/>\n",
    "\n",
    "`Disadvantages:`<br/>\n",
    "‚ñ™ Less efficient for large-scale or production use due to lack of graph optimization.<br/>\n",
    "‚ñ™ Not suitable for hardware relying on static graphs (e.g., TensorFlow Lite, TensorFlow Serving).<br/>\n",
    "\n",
    "**Graph Execution** builds a computational graph of operations, compiles it, and executes it as a whole. Default in TensorFlow 1.x, it‚Äôs still usable in TensorFlow 2.x by disabling eager execution or using specific APIs. Instead of running operations immediately, TensorFlow creates a graph of nodes (operations) and edges (tensors), optimizes it (e.g., removing redundancies or fusing operations), and executes it in a tf.Disable eager execution to use graph mode ‚Üí `tf.compat.v1.disable_eager_execution()` or the `tf.function decorator` to convert eager code into a graph.\n",
    "<br/>\n",
    "\n",
    "`Advantages:`<br/>\n",
    "‚ñ™ Optimized for performance on GPUs/TPUs via graph optimizations.<br/>\n",
    "‚ñ™ Ideal for production deployment needing static graphs (e.g., mobile, servers).<br/> \n",
    "‚ñ™ Supports distributed computing and automatic gradient computation.<br/>\n",
    "\n",
    "`Disadvantages:`<br/>\n",
    "‚ñ™ Debugging is harder as operations run only when the graph executes.<br/>\n",
    "‚ñ™ Requires session management and explicit data feeding, which is less intuitive.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Eager execution is enabled by default in TensorFlow 2.x\n",
    "# This means operations are executed immediately as they are called,\n",
    "# making it easier to debug and work with TensorFlow interactively.\n",
    "\n",
    "# Create a TensorFlow constant tensor `x` with values [1, 2, 3]\n",
    "x = tf.constant([1, 2, 3])\n",
    "\n",
    "# Create another TensorFlow constant tensor `y` with values [4, 5, 6]\n",
    "y = tf.constant([4, 5, 6])\n",
    "\n",
    "# Perform element-wise addition of `x` and `y`\n",
    "# Since eager execution is enabled, the operation is executed immediately,\n",
    "# and the result is computed and stored in `z`.\n",
    "z = x + y\n",
    "\n",
    "# Print the value of `x`\n",
    "# Since `x` is a TensorFlow constant, its value is displayed along with its shape and data type.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager function value: [2. 4.]\n",
      "Graph mode function value: [2. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Define a Python function that performs an operation in eager execution mode\n",
    "def eager_execution(x):\n",
    "    # Add the input tensor to itself using tf.add\n",
    "    x = tf.add(x, x)\n",
    "    # Return the result\n",
    "    return x\n",
    "\n",
    "# Convert the Python function into a TensorFlow graph using tf.function\n",
    "# The resulting `a_function_that_uses_a_graph` is a callable TensorFlow graph\n",
    "a_function_that_uses_a_graph = tf.function(eager_execution)\n",
    "\n",
    "# Create a TensorFlow constant tensor with values [1.0, 2.0]\n",
    "x = tf.constant([1.0, 2.0])\n",
    "\n",
    "# Call the original Python function in eager execution mode\n",
    "# In eager mode, operations are executed immediately as they are called\n",
    "orig_value = eager_execution(x)\n",
    "\n",
    "# Call the TensorFlow graph (converted function) like a Python function\n",
    "# The graph is executed in graph mode, which is optimized for performance\n",
    "tf_function_value = a_function_that_uses_a_graph(x)\n",
    "\n",
    "# Print the results from both the eager execution and graph execution\n",
    "print(f\"Eager function value: {orig_value}\")\n",
    "print(f\"Graph mode function value: {tf_function_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix:\n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "Squared Matrix:\n",
      " tf.Tensor(\n",
      "[[ 7. 10.]\n",
      " [15. 22.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Define a function with the @tf.function decorator\n",
    "# The @tf.function decorator converts the function into a TensorFlow graph,\n",
    "# enabling optimizations like operation fusion and improved performance.\n",
    "@tf.function\n",
    "def matrix_square(matrix):\n",
    "    \"\"\"\n",
    "    Computes the square of a matrix (matrix multiplication with itself).\n",
    "    \n",
    "    Args:\n",
    "        matrix: A 2D tensor (matrix)\n",
    "    \n",
    "    Returns:\n",
    "        The result of matrix @ matrix\n",
    "    \"\"\"\n",
    "    # Perform matrix multiplication using tf.matmul\n",
    "    return tf.matmul(matrix, matrix)\n",
    "\n",
    "# Create a sample input matrix\n",
    "# The input is a 2x2 matrix with float32 values\n",
    "input_matrix = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "# Call the function\n",
    "# The function is executed as a TensorFlow graph, and the result is computed\n",
    "result = matrix_square(input_matrix)\n",
    "\n",
    "# Print the input matrix and the result\n",
    "print(\"Input Matrix:\\n\", input_matrix)\n",
    "print(\"Squared Matrix:\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable eager execution to use TensorFlow 1.x-style graph mode\n",
    "# In graph mode, operations are not executed immediately but are instead added to a graph, which is later executed\n",
    "# within a session.\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Reset any existing default graphs\n",
    "# This clears the current computational graph, ensuring that no previous graph definitions interfere with the new \n",
    "# graph being created.\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Enable eager execution, which allows operations to be executed immediately as they are called\n",
    "# Eager execution is the default mode in TensorFlow 2.x and is more intuitive for debugging and development, as \n",
    "# it behaves like standard Python code.\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node {\n",
      "  name: \"x\"\n",
      "  op: \"Placeholder\"\n",
      "  attr {\n",
      "    key: \"shape\"\n",
      "    value {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 2\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"_user_specified_name\"\n",
      "    value {\n",
      "      s: \"x\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Add\"\n",
      "  op: \"AddV2\"\n",
      "  input: \"x\"\n",
      "  input: \"x\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"Identity\"\n",
      "  op: \"Identity\"\n",
      "  input: \"Add\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "versions {\n",
      "  producer: 1994\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the GraphDef representation of a TensorFlow concrete function\n",
    "print(a_function_that_uses_a_graph.get_concrete_function(x).graph.as_graph_def())\n",
    "\n",
    "# Call the `get_concrete_function` method on the function object, passing `x` as input\n",
    "# This creates a concrete function (a callable TensorFlow graph) for the given input signature\n",
    "# ‚Üí a_function_that_uses_a_graph.get_concrete_function(x)\n",
    "\n",
    "# Access the `graph` attribute of the concrete function, which represents the computation graph\n",
    "# ‚Üí .graph\n",
    "\n",
    "# Convert the computation graph to its GraphDef representation\n",
    "# GraphDef is a protocol buffer that describes the structure of the graph\n",
    "# ‚Üí .as_graph_def()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
