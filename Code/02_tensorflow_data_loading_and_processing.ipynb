{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to Deep Learning with Keras and TensorFlow in Python**\n",
    "\n",
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**<br/>\n",
    "**[GitHub](https://github.com/RezaSaadatyar/Deep-Learning-in-python)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline:**<br/>\n",
    "▪ [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)<br/>\n",
    "▪ [Data Shuffling](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)<br/>\n",
    "▪ [Repeat Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat)<br/>\n",
    "▪ [Batching](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract, Transform, Load (ETL) pipeline:**<br/>\n",
    "▪ `Extract:` Data is gathered from various sources Cloud (e.g., Google Cloud Storage, AWS S3, or Azure Blob Storage), Databases (e.g., MySQL, PostgreSQL), and Local File System (this might include CSV files, JSON files, or other raw data stored locally).<br/>\n",
    "▪ `Transform:` Data is processed, cleaned, or reformatted to make it suitable for analysis or model training. Common transformations include: normalizing numerical data (e.g., scaling values between 0 and 1), encoding categorical data (e.g., one-hot encoding), handling missing values, and resizing images or tokenizing text (if working with image or NLP datasets).<br/>\n",
    "▪ `Load:` The transformed data is loaded into a target system, such as a device or storage for further use.<br/>\n",
    "\n",
    "`tf.data` a TensorFlow API, streamlines loading, preprocessing, and feeding data into models. It excels with large datasets, supporting streaming and parallel processing for efficiency. \n",
    "\n",
    "**Key tf.data methods for extraction:**<br/>\n",
    "▪ `tf.data.Dataset.from_tensor_slices():` Create a dataset from in-memory tensors (e.g., NumPy arrays).<br/>\n",
    "▪ `tf.data.TextLineDataset:` Load text files line by line (e.g., for CSVs or raw text).<br/>\n",
    "▪ `tf.data.TFRecordDataset:` Load data stored in TFRecord format, which is optimized for TensorFlow.<br/>\n",
    "▪ `tf.keras.utils.image_dataset_from_directory(): `Load image datasets directly from a directory structure (useful for image classification tasks).<br/>\n",
    "\n",
    "**Key tf.data methods for transformation:**<br/>\n",
    "▪ `dataset.map():` Apply a transformation function to each element.<br/>\n",
    "▪ `dataset.filter():` Filter out elements based on a condition.<br/>\n",
    "▪ `dataset.shuffle():` Randomize the dataset.<br/>\n",
    "▪ `dataset.batch():` Group elements into batches.<br/>\n",
    "\n",
    "▪ <br/>\n",
    "▪ <br/>\n",
    "▪ <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>,\n",
       " array([ 8,  3, 20, -1,  0,  1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a NumPy array with the given values\n",
    "x = np.array([8, 3, 20, -1, 0, 1])\n",
    "\n",
    "# Create a TensorFlow Dataset from the NumPy array using tf.data.Dataset.from_tensor_slices\n",
    "# This creates a dataset where each element is a slice of the input array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "# The dataset is now ready for iteration or further processing\n",
    "dataset, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=8>\n",
      "1 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=3>\n",
      "2 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=20>\n",
      "3 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=-1>\n",
      "4 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=0>\n",
      "5 → tensor = <tf.Tensor: shape=(), dtype=int64, numpy=1>\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataset and print each element along with its index\n",
    "for ind, tensor in enumerate(dataset):\n",
    "    print(f\"{ind} → {tensor = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.int64, name=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the element specification of the dataset\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor with random uniform values (shape [100, 5])\n",
    "x = tf.random.uniform([100, 5])\n",
    "\n",
    "# Create a 1D tensor with random uniform integer values (shape [100]) ranging from 0 to 1\n",
    "y = tf.random.uniform([100], maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Create a TensorFlow Dataset from a tuple of tensors (x, y) using tf.data.Dataset.from_tensor_slices\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "# Inspect the element specification of the dataset\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TensorFlow Dataset from the 2D tensor `x` using tf.data.Dataset.from_tensor_slices\n",
    "x_dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "# Create a TensorFlow Dataset from the 1D tensor `y` using tf.data.Dataset.from_tensor_slices\n",
    "y_dataset = tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "# Combine the two datasets into a single dataset using tf.data.Dataset.zip\n",
    "# This pairs each element of `x_dataset` with the corresponding element of `y_dataset`\n",
    "dataset = tf.data.Dataset.zip((x_dataset, y_dataset))\n",
    "\n",
    "# Inspect the element specification of the original dataset\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 → [0.69098985 0.80467045 0.7604947  0.0914799  0.6327827 ]\n",
      "1 → [0.99304974 0.5970018  0.21458507 0.7159656  0.7758702 ]\n",
      "1 → [0.31689167 0.5630431  0.2784543  0.00234151 0.65439403]\n",
      "1 → [0.50773513 0.10693932 0.40303254 0.27550995 0.6557487 ]\n",
      "0 → [0.4887359  0.44025254 0.05140471 0.75439227 0.35550952]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the first 5 elements of the dataset and print each pair of (x, y) values\n",
    "for ind_x, ind_y in dataset.take(5):\n",
    "    print(f\"{ind_y} → {ind_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_y = <tf.Tensor: shape=(), dtype=int32, numpy=0> → ind_x = <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.69098985, 0.80467045, 0.7604947 , 0.0914799 , 0.6327827 ],\n",
      "      dtype=float32)>\n",
      "ind_y = <tf.Tensor: shape=(), dtype=int32, numpy=1> → ind_x = <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.99304974, 0.5970018 , 0.21458507, 0.7159656 , 0.7758702 ],\n",
      "      dtype=float32)>\n",
      "ind_y = <tf.Tensor: shape=(), dtype=int32, numpy=1> → ind_x = <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.31689167, 0.5630431 , 0.2784543 , 0.00234151, 0.65439403],\n",
      "      dtype=float32)>\n",
      "ind_y = <tf.Tensor: shape=(), dtype=int32, numpy=1> → ind_x = <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.50773513, 0.10693932, 0.40303254, 0.27550995, 0.6557487 ],\n",
      "      dtype=float32)>\n",
      "ind_y = <tf.Tensor: shape=(), dtype=int32, numpy=0> → ind_x = <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.4887359 , 0.44025254, 0.05140471, 0.75439227, 0.35550952],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "for ind_x, ind_y in dataset.take(5):\n",
    "    print(f\"{ind_y = } → {ind_x = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 → [0.50773513 0.10693932 0.40303254 0.27550995 0.6557487 ]\n",
      "1 → [0.39901233 0.60831    0.1106385  0.68864775 0.3791287 ]\n",
      "1 → [0.31689167 0.5630431  0.2784543  0.00234151 0.65439403]\n",
      "1 → [0.6434109  0.12706244 0.13220489 0.9911444  0.3176396 ]\n",
      "1 → [0.99304974 0.5970018  0.21458507 0.7159656  0.7758702 ]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataset with a buffer size of 5\n",
    "# The `shuffle` method randomly shuffles the elements of the dataset using a buffer\n",
    "dataset = dataset.shuffle(buffer_size=5)\n",
    "\n",
    "# Iterate over the first 5 elements of the shuffled dataset and print each pair of (x, y) values\n",
    "for ind_x, ind_y in dataset.take(5):\n",
    "    print(f\"{ind_y} → {ind_x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Create a 1D tensor with values [0, 1, 2] using tf.range\n",
    "x = tf.range(3)\n",
    "\n",
    "# Create a TensorFlow Dataset from the tensor using tf.data.Dataset.from_tensor_slices\n",
    "x_dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "\n",
    "# Repeat the dataset 2 times using the `repeat` method\n",
    "# This creates a dataset that iterates through the original dataset twice\n",
    "ds = x_dataset.repeat(2)\n",
    "\n",
    "# Iterate over the first 10 elements of the repeated dataset and print each element\n",
    "for ind_x in ds.take(10):\n",
    "    print(ind_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Create a TensorFlow Dataset with values from 0 to 99 using tf.data.Dataset.range\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "\n",
    "# Iterate over the first 5 elements of the dataset and print each element\n",
    "for ind in dataset.take(5):\n",
    "    print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7], shape=(4,), dtype=int64)\n",
      "tf.Tensor([ 8  9 10 11], shape=(4,), dtype=int64)\n",
      "tf.Tensor([12 13 14 15], shape=(4,), dtype=int64)\n",
      "tf.Tensor([16 17 18 19], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Batch the dataset into groups of 4 elements using the `batch` method\n",
    "ds = dataset.batch(4)\n",
    "\n",
    "# Iterate over the first 5 batches of the dataset and print each batch\n",
    "for ind in ds.take(5):\n",
    "    print(ind)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
